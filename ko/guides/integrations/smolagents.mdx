# Smolagents

<Warning>
  이 페이지에 표시된 모든 코드 샘플은 Python으로 작성되었습니다.
</Warning>

이 페이지에서는 [Smolagents](https://huggingface.co/docs/smolagents/en/index)를 W\&B Weave와 통합하여 에이전트 애플리케이션을 추적하고 분석하는 방법을 설명합니다. 모델 추론을 기록하고, 함수 호출을 모니터링하며, Weave의 추적 및 버전 관리 기능을 사용하여 실험을 구성하는 방법을 배우게 됩니다. 제공된 예제를 따라하면 귀중한 인사이트를 캡처하고, 애플리케이션을 효율적으로 디버깅하며, 다양한 모델 구성을 비교할 수 있습니다—모두 Weave 웹 인터페이스 내에서 가능합니다.

## 개요

Smolagents는 강력한 에이전트 애플리케이션을 구축하기 위한 최소한의 추상화를 제공하는 간단한 프레임워크입니다. OpenAI, Hugging Face Transformers, Anthropic과 같은 여러 LLM 제공업체를 지원합니다.

Weave는 자동으로 [Smolagents](https://huggingface.co/docs/smolagents/en/index)에 대한 추적을 캡처합니다. 추적을 시작하려면 `weave.init()`를 호출하고 라이브러리를 평소와 같이 사용하세요.

## 사전 요구 사항

1. Smolagents를 Weave와 함께 사용하기 전에 필요한 라이브러리를 설치하거나 최신 버전으로 업그레이드하세요. 다음 명령은 `smolagents`, `openai`, 및 `weave`를 설치하거나 업그레이드하고, 출력을 억제합니다:

   ```python
   pip install -U smolagents openai weave -qqq
   ```

2. Smolagents는 OpenAI, Hugging Face Transformers, Anthropic과 같은 여러 LLM 제공업체를 지원합니다. 선택한 제공업체의 API 키를 해당 환경 변수를 설정하여 지정하세요:

   ```python
   import os
   import getpass

   os.environ["OPENAI_API_KEY"] = getpass.getpass("Enter your OpenAI API key: ")
   ```

## 기본 추적

언어 모델 애플리케이션의 추적을 중앙 위치에 저장하는 것은 개발 및 프로덕션 중에 필수적입니다. 이러한 추적은 디버깅에 도움이 되며 애플리케이션을 개선하기 위한 귀중한 데이터셋으로 활용됩니다.

Weave는 자동으로 [Smolagents](https://huggingface.co/docs/smolagents/en/index)에 대한 추적을 캡처합니다. 추적을 시작하려면 `weave.init()`를 호출하여 Weave를 초기화한 다음 라이브러리를 평소와 같이 사용하세요.

다음 예제는 Weave를 사용하여 도구를 사용하는 LLM 에이전트에 대한 추론 호출을 기록하는 방법을 보여줍니다. 이 시나리오에서는:

* Smolagents의 `gpt-4o`를 사용하여 언어 모델(OpenAI의 `OpenAIServerModel`)을 정의합니다.
* 에이전트가 필요할 때 호출할 수 있는 검색 도구(`DuckDuckGoSearchTool`)를 구성합니다.
* 도구와 모델을 전달하여 `ToolCallingAgent`를 구성합니다.
* 검색 도구를 트리거하는 쿼리를 에이전트를 통해 실행합니다.
* Weave는 각 함수 및 모델 호출을 기록하여 웹 인터페이스를 통해 검사할 수 있도록 합니다.

```python
import weave
from smolagents import DuckDuckGoSearchTool, OpenAIServerModel, ToolCallingAgent

# Initialize Weave
weave.init(project_name="smolagents")

# Define your LLM provider supported by Smolagents
model = OpenAIServerModel(model_id="gpt-4o")

# Define a DuckDuckGo web search tool based on your query
search_tool = DuckDuckGoSearchTool()

# Define a tool-calling agent
agent = ToolCallingAgent(tools=[search_tool], model=model)
answer = agent.run(
    "Get me just the title of the page at url 'https://wandb.ai/geekyrakshit/story-illustration/reports/Building-a-GenAI-assisted-automatic-story-illustrator--Vmlldzo5MTYxNTkw'?"
)
```

코드 샘플을 실행한 후 Weave 프로젝트 대시보드로 이동하여 추적을 확인하세요.

![Weave logs each inference call, providing details about inputs, outputs, and metadata.](./imgs/smolagents-trace.png)

## 사용자 정의 도구 추적

에이전트 워크플로우를 위한 사용자 정의 도구는 `@tool`로 함수를 장식하거나 `smolagents`에서 가져온 `smolagents.Tool` 클래스를 상속받아 선언할 수 있습니다.

Weave는 Smolagents 워크플로우에 대한 사용자 정의 도구 호출을 자동으로 추적합니다. 다음 예제는 Weave로 사용자 정의 Smolagents 도구 호출을 기록하는 방법을 보여줍니다:

* 사용자 정의 `get_weather` 함수가 정의되고 Smolagents의 `@tool`로 장식되어 에이전트가 추론 과정의 일부로 이를 호출할 수 있게 합니다.
* 이 함수는 위치와 섭씨 출력을 위한 선택적 플래그를 받습니다.
* 언어 모델은 `OpenAIServerModel`를 사용하여 인스턴스화됩니다.
* 사용자 정의 도구와 모델로 `ToolCallingAgent`가 생성됩니다.
* 에이전트가 쿼리를 실행할 때, `get_weather` 도구를 선택하고 호출합니다.
* Weave는 모델 추론과 사용자 정의 도구 호출을 모두 기록하며, 인수와 반환 값을 포함합니다.

```python
from typing import Optional

import weave
from smolagents import OpenAIServerModel, ToolCallingAgent, tool

weave.init(project_name="smolagents")

@tool
def get_weather(location: str, celsius: Optional[bool] = False) -> str:
    """
    Get the weather in the next few days for a given location.
    Args:
        location: The location.
        celsius: Whether to use Celsius for temperature.
    """
    return f"The weather in {location} is sunny with temperatures around 7°C."

model = OpenAIServerModel(model_id="gpt-4o")
agent = ToolCallingAgent(tools=[get_weather], model=model)
answer = agent.run("What is the weather in Tokyo?")
```

코드 샘플을 실행한 후 Weave 프로젝트 대시보드로 이동하여 추적을 확인하세요.

![Weave logs each custom tool call.](./imgs/smolagents-custom-tool.png)
