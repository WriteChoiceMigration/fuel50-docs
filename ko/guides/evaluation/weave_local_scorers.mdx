---
- title: Weave 로컬 평가기
- description: AI 시스템의 안전성과 품질을 평가하기 위해 로컬에서 실행되는 소형 언어 모델
---

<a target="_blank" href="https://colab.research.google.com/github/wandb/examples/blob/master/weave/docs/scorers_local_weave_scorers.ipynb">
  <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" />
</a>

Weave의 로컬 스코러는 최소한의 지연 시간으로 사용자의 기기에서 로컬로 실행되는 소형 언어 모델 모음입니다. 이러한 모델은 AI 시스템의 입력, 컨텍스트 및 출력의 안전성과 품질을 평가합니다.

이러한 모델 중 일부는 Weights & Biases에 의해 미세 조정되었으며, 다른 일부는 커뮤니티에서 훈련한 최첨단 오픈 소스 모델입니다. 훈련 및 평가에는 Weights & Biases(W\&B) Reports가 사용되었습니다. 전체 세부 정보는 다음에서 확인할 수 있습니다 [W\&B Reports 목록](https://wandb.ai/c-metrics/weave-scorers/reports/Weave-Scorers-v1--VmlldzoxMDQ0MDE1OA).

모델 가중치는 W\&B Artifacts에서 공개적으로 사용 가능하며, 스코러 클래스를 인스턴스화할 때 자동으로 다운로드됩니다. 직접 다운로드하려면 다음에서 아티팩트 경로를 찾을 수 있습니다: `weave.scorers.default_models`

이러한 스코러가 반환하는 객체에는 `passed` 입력 텍스트가 안전하거나 고품질인지 나타내는 boolean 속성과 `metadata` 모델의 원시 점수와 같은 더 자세한 정보를 포함하는 속성이 있습니다.

<Tip>
  로컬 스코러는 CPU와 GPU에서 실행할 수 있지만, 최상의 성능을 위해 GPU를 사용하세요.
</Tip>

<Tabs>
  <Tab title="Python">
    ## 사전 요구 사항

    Weave 로컬 스코러를 사용하기 전에 추가 종속성을 설치하세요:

    ```bash
    pip install weave[scorers]
    ```

    ## 스코러 선택

    다음과 같은 로컬 스코러를 사용할 수 있습니다. 사용 사례에 따라 스코러를 선택하세요.

    | 스코러                                                             | 시나리오                                                                       |
    | --------------------------------------------------------------- | -------------------------------------------------------------------------- |
    | [WeaveToxicityScorerV1](#weavetoxicityscorerv1)                 | AI 시스템의 입력 및 출력에서 혐오 발언이나 위협 등 유해하거나 독성이 있는 콘텐츠를 식별합니다.                    |
    | [WeaveBiasScorerV1](#weavebiasscorerv1)                         | AI 시스템의 입력 및 출력에서 편향되거나 고정관념적인 콘텐츠를 감지합니다. 생성된 텍스트에서 유해한 편향을 줄이는 데 이상적입니다. |
    | [WeaveHallucinationScorerV1](#weavehallucinationscorerv1)       | RAG 시스템이 제공된 입력 및 컨텍스트를 기반으로 출력에서 환각을 생성하는지 식별합니다.                         |
    | [WeaveContextRelevanceScorerV1](#weavecontextrelevancescorerv1) | AI 시스템의 출력이 제공된 입력 및 컨텍스트와 관련이 있는지 측정합니다.                                  |
    | [WeaveCoherenceScorerV1](#weavecoherencescorerv1)               | AI 시스템 출력의 일관성과 논리적 구조를 평가합니다.                                             |
    | [WeaveFluencyScorerV1](#weavefluencyscorerv1)                   | AI 시스템의 출력이 유창한지 측정합니다.                                                    |
    | [WeaveTrustScorerV1](#weavetrustscorerv1)                       | 독성, 환각, 컨텍스트 관련성, 유창성 및 일관성 스코러를 활용하는 집계 스코러입니다.                           |
    | [PresidioScorer](#presidioscorer)                               | Microsoft의 Presidio 라이브러리를 사용하여 AI 시스템의 입력 및 출력에서 개인 식별 정보(PII)를 감지합니다.    |

    ## `WeaveBiasScorerV1`

    이 스코러는 두 가지 차원에서 성별 및 인종/출신 편향을 평가합니다:

    * 인종 및 출신: 인종차별 및 국가나 지역 출신, 이민 상태, 민족성 등에 대한 편향.
    * 성별 및 성적 지향: 성차별, 여성 혐오, 동성애 혐오, 트랜스젠더 혐오, 성희롱 등.

    `WeaveBiasScorerV1`는 미세 조정된 [deberta-small-long-nli](https://huggingface.co/tasksource/deberta-small-long-nli) 모델을 사용합니다. 모델, 데이터셋 및 보정 프로세스에 대한 자세한 내용은 [WeaveBiasScorerV1 W\&B Report](https://wandb.ai/c-metrics/bias-benchmark/reports/Bias-Scorer--VmlldzoxMDM2MTgzNw)를 참조하세요.

    ### 사용 참고 사항

    * 이 `score` 메서드는 `output` 매개변수에 문자열을 전달해야 합니다.
    * 점수가 높을수록 텍스트에서 편향에 대한 예측이 더 강합니다.
    * 이 `threshold` 매개변수는 설정되어 있지만 초기화 시 재정의할 수도 있습니다.

    ### 사용 예시

    ```python
    import weave
    from weave.scorers import WeaveBiasScorerV1

    bias_scorer = WeaveBiasScorerV1()
    result = bias_scorer.score(output="Martian men are terrible at cleaning")

    print(f"The text is biased: {not result.passed}")
    print(result)
    ```

    ***

    ## `WeaveToxicityScorerV1`

    이 스코러는 다섯 가지 차원에서 입력 텍스트의 독성을 평가합니다:

    * 인종 및 출신: 인종차별 및 국가나 지역 출신, 이민 상태, 민족성 등에 대한 편향.
    * 성별 및 성적 지향: 성차별, 여성 혐오, 동성애 혐오, 트랜스젠더 혐오, 성희롱 등.
    * Religious: Bias or stereotypes against someone's religion.
    * Ability: Bias related to someone's physical, mental, or intellectual ability or disability.
    * 폭력 및 학대: 폭력에 대한 지나치게 그래픽한 묘사, 폭력 위협 또는 폭력 선동.

    이 `WeaveToxicityScorerV1`는 오픈 소스 [Celadon](https://huggingface.co/PleIAs/celadon) 모델을 PleIAs에서 사용합니다. 자세한 내용은 [WeaveToxicityScorerV1 W\&B Report](https://wandb.ai/c-metrics/toxicity-benchmark/reports/Toxicity-Scorer--VmlldzoxMDMyNjc0NQ)를 참조하세요.

    ### 사용 참고 사항

    * 이 `score` 메서드는 `output` 매개변수에 문자열을 전달해야 합니다.
    * 이 모델은 `0`에서 `3`까지 다섯 가지 다른 카테고리에 대한 점수를 반환합니다:
      * 이러한 점수의 합계가 `total_threshold` (기본값 `5`) 이상이면 입력이 독성이 있는 것으로 표시됩니다.
      * 단일 카테고리의 점수가 `category_threshold` (기본값 `2`) 이상이면 입력이 독성이 있는 것으로 표시됩니다.
    * 필터링을 더 적극적으로 만들려면 초기화 중에 `category_threshold` 또는 `total_threshold`를 재정의하세요.

    ### 사용 예시

    ```python
    import weave
    from weave.scorers import WeaveToxicityScorerV1

    toxicity_scorer = WeaveToxicityScorerV1()
    result = toxicity_scorer.score(output="people from the south pole of Mars are the worst")

    print(f"Input is toxic: {not result.passed}")
    print(result)
    ```

    ***

    ## `WeaveHallucinationScorerV1`

    이 스코러는 AI 시스템의 출력에 입력 데이터를 기반으로 한 환각이 포함되어 있는지 확인합니다.

    이 `WeaveHallucinationScorerV1`는 오픈 소스 [HHEM 2.1 model](https://huggingface.co/vectara/hallucination_evaluation_model)을 Vectara에서 사용합니다. 자세한 내용은 [WeaveHallucinationScorerV1 W\&B Report](https://wandb.ai/c-metrics/hallucination/reports/Hallucination-Scorer--VmlldzoxMDM3NDA3MA)를 참조하세요.

    ### 사용 참고 사항

    * 이 `score` 메서드는 `query`와 `output` 매개변수에 값을 전달해야 합니다.
    * 컨텍스트는 `output` 매개변수에 전달해야 합니다(문자열 또는 문자열 목록으로).
    * 출력 점수가 높을수록 출력에서 환각에 대한 예측이 더 강합니다.
    * 이 `threshold` 매개변수는 설정되어 있지만 초기화 시 재정의할 수 있습니다.

    ### 사용 예시

    ```python
    import weave
    from weave.scorers import WeaveHallucinationScorerV1

    hallucination_scorer = WeaveHallucinationScorerV1()

    result = hallucination_scorer.score(
        query="What is the capital of Antarctica?",
        context="People in Antarctica love the penguins.",
        output="While Antarctica is known for its sea life, penguins aren't liked there."
    )

    print(f"Output is hallucinated: {not result.passed}")
    print(result)
    ```

    ***

    ## `WeaveContextRelevanceScorerV1`

    이 스코러는 RAG 시스템을 평가할 때 사용하도록 설계되었습니다. 쿼리에 대한 컨텍스트의 관련성을 점수화합니다.

    이 `WeaveContextRelevanceScorerV1`는 미세 조정된 [deberta-small-long-nli](https://huggingface.co/tasksource/deberta-small-long-nli) 모델을 tasksource에서 사용합니다. 자세한 내용은 [WeaveContextRelevanceScorerV1 W\&B Report](https://wandb.ai/c-metrics/context-relevance-scorer/reports/Context-Relevance-Scorer--VmlldzoxMDYxNjEyNA)를 참조하세요.

    ### 사용 참고 사항

    * 이 `score` 메서드는 `query`와 `output` 값을 기대합니다.
    * 컨텍스트는 `output` 매개변수에 전달해야 합니다(문자열 또는 문자열 목록).
    * 점수가 높을수록 컨텍스트가 쿼리와 관련이 있다는 예측이 더 강합니다.
    * 청크별 점수를 얻으려면 `verbose=True`를 `score` 메서드에 전달할 수 있습니다.

    ### 사용 예시

    ```python
    import weave
    from weave.scorers import WeaveContextRelevanceScorerV1

    context_relevance_scorer = WeaveContextRelevanceScorerV1()

    result = context_relevance_scorer.score(
        query="What is the capital of Antarctica?",
        output="The Antarctic has the happiest penguins."  # context is passed to the output parameter
    )

    print(f"Output is relevant: {result.passed}")
    print(result)
    ```

    ## `WeaveCoherenceScorerV1`

    이 스코러는 입력 텍스트가 일관성이 있는지 확인합니다.

    이 `WeaveCoherenceScorerV1`는 미세 조정된 [deberta-small-long-nli](https://huggingface.co/tasksource/deberta-small-long-nli) 모델을 tasksource에서 사용합니다. 자세한 내용은 [WeaveCoherenceScorerV1 W\&B Report](https://wandb.ai/c-metrics/coherence_scorer/reports/Coherence-Scorer--VmlldzoxMDI5MjA1MA).

    ### 사용 참고사항

    * The `score` method expects text to be passed to the `query` and `output` parameters.
    * 더 높은 출력 점수는 일관성에 대한 더 강한 예측을 의미합니다.

    ### 사용 예시

    ```python
    import weave
    from weave.scorers import WeaveCoherenceScorerV1

    coherence_scorer = WeaveCoherenceScorerV1()

    result = coherence_scorer.score(
        query="What is the capital of Antarctica?",
        output="but why not monkey up day"
    )

    print(f"Output is coherent: {result.passed}")
    print(result)
    ```

    ***

    ## `WeaveFluencyScorerV1`

    이 평가기는 입력 텍스트가 유창한지—즉, 자연스러운 인간 언어와 유사하게 읽고 이해하기 쉬운지 평가합니다. 문법, 구문 및 전반적인 가독성을 평가합니다.

    The `WeaveFluencyScorerV1` uses a fine-tuned [ModernBERT-base](https://huggingface.co/answerdotai/ModernBERT-base) model from AnswerDotAI. For more information, see the [WeaveFluencyScorerV1 W\&B Report](https://wandb.ai/c-metrics/fluency-eval/reports/Fluency-Scorer--VmlldzoxMTA3NzE2Ng).

    ### 사용 참고사항

    * The `score` method expects text to be passed to the `output` parameter.
    * 더 높은 출력 점수는 더 높은 유창성을 나타냅니다.

    ### 사용 예시

    ```python
    import weave
    from weave.scorers import WeaveFluencyScorerV1

    fluency_scorer = WeaveFluencyScorerV1()

    result = fluency_scorer.score(
        output="The cat did stretching lazily into warmth of sunlight."
    )

    print(f"Output is fluent: {result.passed}")
    print(result)
    ```

    ***

    ## `WeaveTrustScorerV1`

    The `WeaveTrustScorerV1` is a composite scorer for RAG systems that evaluates the trustworthiness of model outputs by grouping other scorers into two categories: Critical and Advisory. Based on the composite score, it returns a trust level:

    * `high`: 문제가 감지되지 않음
    * `medium`: Advisory 문제만 감지됨
    * `low`: Critical 문제가 감지되거나 입력이 비어 있음

    Critical 평가기에서 실패한 모든 입력은 `low` trust level로 결과가 나옵니다. Advisory 평가기에서 실패하면 `medium`.

    * **Critical:**
      * `WeaveToxicityScorerV1`
      * `WeaveHallucinationScorerV1`
      * `WeaveContextRelevanceScorerV1`

    * **Advisory:**
      * `WeaveFluencyScorerV1`
      * `WeaveCoherenceScorerV1`

    ### 사용 참고사항

    * 이 평가기는 RAG 파이프라인을 평가하기 위해 설계되었습니다.
    * It requires `query`, `context`, and `output` keys for correct scoring.

    ### 사용 예시

    ```python
    import weave
    from weave.scorers import WeaveTrustScorerV1

    trust_scorer = WeaveTrustScorerV1()

    def print_trust_scorer_result(result):
        print()
        print(f"Output is trustworthy: {result.passed}")
        print(f"Trust level: {result.metadata['trust_level']}")
        if not result.passed:
            print("Triggered scorers:")
            for scorer_name, scorer_data in result.metadata['raw_outputs'].items():
                if not scorer_data.passed:
                    print(f"  - {scorer_name} did not pass")
        print()
        print(f"WeaveToxicityScorerV1 scores: {result.metadata['scores']['WeaveToxicityScorerV1']}")
        print(f"WeaveHallucinationScorerV1 scores: {result.metadata['scores']['WeaveHallucinationScorerV1']}")
        print(f"WeaveContextRelevanceScorerV1 score: {result.metadata['scores']['WeaveContextRelevanceScorerV1']}")
        print(f"WeaveCoherenceScorerV1 score: {result.metadata['scores']['WeaveCoherenceScorerV1']}")
        print(f"WeaveFluencyScorerV1: {result.metadata['scores']['WeaveFluencyScorerV1']}")
        print()

    result = trust_scorer.score(
        query="What is the capital of Antarctica?",
        context="People in Antarctica love the penguins.",
        output="The cat stretched lazily in the warm sunlight."
    )

    print_trust_scorer_result(result)
    print(result)
    ```

    ***

    ## `PresidioScorer`

    이 평가기는 [Presidio library](https://github.com/microsoft/presidio)를 사용하여 AI 시스템의 입력 및 출력에서 개인 식별 정보(PII)를 감지합니다.

    ### 사용 참고사항

    * 이메일이나 전화번호와 같은 특정 엔티티 유형을 지정하려면 Presidio 엔티티 목록을 `selected_entities` 매개변수에 전달하세요. 그렇지 않으면 Presidio는 기본 엔티티 목록에 있는 모든 엔티티 유형을 감지합니다.
    * 이메일이나 전화번호와 같은 특정 엔티티 유형을 감지하려면 목록을 `selected_entities` 매개변수에 전달하세요.
    * 사용자 정의 인식기는 `custom_recognizers` 매개변수를 통해 `presidio.EntityRecognizer` 인스턴스 목록으로 전달할 수 있습니다.
    * 영어가 아닌 입력을 처리하려면 `language` 매개변수를 사용하여 언어를 지정하세요.

    ### 사용 예시

    ```python
    import weave
    from weave.scorers import PresidioScorer

    presidio_scorer = PresidioScorer()

    result = presidio_scorer.score(
        output="Mary Jane is a software engineer at XYZ company and her email is mary.jane@xyz.com."
    )

    print(f"Output contains PII: {not result.passed}")
    print(result)
    ```
  </Tab>

  <Tab title="TypeScript">
    Weave 로컬 평가기는 아직 TypeScript에서 사용할 수 없습니다. 계속 지켜봐 주세요!

    TypeScript에서 Weave 평가기를 사용하려면 [function-based scorers](scorers#function-based-scorers)를 참조하세요.
  </Tab>
</Tabs>
