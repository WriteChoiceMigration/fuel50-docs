---
- title: モデル
- description: データとコードを組み合わせた構造化モデルでアプリケーションをバージョン管理する
---

`Model` は、データ（設定、トレーニング済みモデルの重み、またはその他の情報を含む場合がある）とモデルの動作方法を定義するコードの組み合わせです。このAPIと互換性があるようにコードを構造化することで、実験を体系的に追跡できるように、アプリケーションをバージョン管理する構造化された方法の恩恵を受けることができます。

<Tabs>
  <Tab title="Python">
    Weaveでモデルを作成するには、以下が必要です：

    * から継承するクラス `weave.Model`
    * すべてのパラメータの型定義
    * 型付けされた `predict` 関数と `@weave.op()` デコレータ

    ```python
    from weave import Model
    import weave

    class YourModel(Model):
        attribute1: str
        attribute2: int

        @weave.op()
        def predict(self, input_data: str) -> dict:
            # Model logic goes here
            prediction = self.attribute1 + ' ' + input_data
            return {'pred': prediction}
    ```

    通常通りモデルを呼び出すことができます：

    ```python
    import weave
    weave.init('intro-example')

    model = YourModel(attribute1='hello', attribute2=5)
    model.predict('world')
    ```

    これにより、`predict` を呼び出すたびに、モデル設定と入出力が追跡されます。

    ## モデルの自動バージョン管理

    モデルを定義するパラメータやコードを変更すると、これらの変更が記録され、バージョンが更新されます。
    これにより、異なるバージョンのモデル間で予測を比較できます。これを使用してプロンプトを反復的に改善したり、最新のLLMを試して、異なる設定間で予測を比較したりできます。

    例えば、ここで新しいモデルを作成します：

    ```python
    import weave
    weave.init('intro-example')

    model = YourModel(attribute1='howdy', attribute2=10)
    model.predict('world')
    ```

    これを呼び出した後、UIにこのモデルの2つのバージョンが表示され、それぞれ異なる追跡された呼び出しがあることがわかります。

    ## モデルの提供

    モデルを提供するには、以下を呼び出すだけでFastAPIサーバーを簡単に起動できます：

    ```bash
    weave serve <your model ref>
    ```

    追加の指示については、[serve](/ja/guides/tools/serve) をご覧ください。

    ## 本番呼び出しの追跡

    本番呼び出しを分離するには、UIまたはAPIで簡単にフィルタリングできるように、予測に追加の属性を追加できます。

    ```python
    with weave.attributes({'env': 'production'}):
        model.predict('world')
    ```
  </Tab>

  <Tab title="TypeScript">
    ```plaintext
    This feature is not available in TypeScript yet.  Stay tuned!
    ```
  </Tab>
</Tabs>
