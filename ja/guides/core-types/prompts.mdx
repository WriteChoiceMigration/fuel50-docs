---
- title: Prompts
- description: LLMアプリケーション用のプロンプトを保存、バージョン管理、整理する
---

<Warning>
  この機能はPython SDKを通じてのみアクセス可能です。このページのすべてのコード例はPythonで提供されています。
</Warning>

プロンプトの作成、評価、改良はAIエンジニアの中核的な活動です。
プロンプトの小さな変更がアプリケーションの動作に大きな影響を与えることがあります。
Weaveを使用すると、プロンプトを作成し、保存して取得し、時間の経過とともに進化させることができます。

WeaveはPromptの構築方法について特定の意見を持ちません。シンプルなニーズであれば、組み込みの`weave.StringPrompt`または`weave.MessagesPrompt`クラス。あなたのニーズがより複雑な場合は、それらまたは基本クラスをサブクラス化することができます`weave.Prompt`そしてオーバーライドする

`format`メソッド。

これらのオブジェクトを`weave.publish`で公開すると、Weaveプロジェクトの「Prompts」ページに表示されます。

## StringPrompt

```python
import weave
weave.init('intro-example')

# highlight-next-line
system_prompt = weave.StringPrompt("You are a pirate")
# highlight-next-line
weave.publish(system_prompt, name="pirate_prompt")

from openai import OpenAI
client = OpenAI()

response = client.chat.completions.create(
  model="gpt-4o",
  messages=[
    {
      "role": "system",
      # highlight-next-line
      "content": system_prompt.format()
    },
    {
      "role": "user",
      "content": "Explain general relativity in one paragraph."
    }
  ],
)
```

おそらくこのプロンプトは望ましい効果を生み出さないため、より明確に指示するようにプロンプトを修正します。

```python
import weave
weave.init('intro-example')

# highlight-next-line
system_prompt = weave.StringPrompt("Talk like a pirate. I need to know I'm listening to a pirate.")
weave.publish(system_prompt, name="pirate_prompt")

from openai import OpenAI
client = OpenAI()

response = client.chat.completions.create(
  model="gpt-4o",
  messages=[
    {
      "role": "system",
      # highlight-next-line
      "content": system_prompt.format()
    },
    {
      "role": "user",
      "content": "Explain general relativity in one paragraph."
    }
  ],
)
```

このプロンプトオブジェクトを表示すると、2つのバージョンがあることがわかります。

![Screenshot of viewing a prompt object](imgs/prompt-object.png)

また、比較のために選択して、何が変更されたかを正確に確認することもできます。

![Screenshot of prompt comparison](imgs/prompt-comparison.png)

## MessagesPrompt

この`MessagesPrompt`はMessageオブジェクトの配列を置き換えるために使用できます。

```python
import weave
weave.init('intro-example')

# highlight-next-line
prompt = weave.MessagesPrompt([
    {
        "role": "system",
        "content": "You are a stegosaurus, but don't be too obvious about it."
    },
    {
        "role": "user",
        "content": "What's good to eat around here?"
    }
])
weave.publish(prompt, name="dino_prompt")

from openai import OpenAI
client = OpenAI()

response = client.chat.completions.create(
  model="gpt-4o",
  # highlight-next-line
  messages=prompt.format(),
)
```

## プロンプトのパラメータ化

この`format`メソッドの名前が示すように、コンテンツ文字列内のテンプレートプレースホルダーを埋めるために引数を渡すことができます。

```python
import weave
weave.init('intro-example')

# highlight-next-line
prompt = weave.StringPrompt("Solve the equation {equation}")
weave.publish(prompt, name="calculator_prompt")

from openai import OpenAI
client = OpenAI()

response = client.chat.completions.create(
  model="gpt-4o",
  messages=[
    {
      "role": "user",
      # highlight-next-line
      "content": prompt.format(equation="1 + 1 = ?")
    }
  ],
)
```

これは`MessagesPrompt`でも機能します。

```python
import weave
weave.init('intro-example')

# highlight-next-line
prompt = weave.MessagesPrompt([
{
    "role": "system",
    "content": "You will be provided with a description of a scene and your task is to provide a single word that best describes an associated emotion."
},
{
    "role": "user",
    "content": "{scene}"
}
])
weave.publish(prompt, name="emotion_prompt")

from openai import OpenAI
client = OpenAI()

response = client.chat.completions.create(
  model="gpt-4o",
  # highlight-next-line
  messages=prompt.format(scene="A dog is lying on a dock next to a fisherman."),
)
```
