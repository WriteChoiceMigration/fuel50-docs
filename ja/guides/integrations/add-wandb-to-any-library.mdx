---
- title: 任意のライブラリにwandbを追加する
---

* [ホーム](/)
* [インテグレーション](/ja/guides/integrations)
* 任意のライブラリにwandbを追加する

このページの内容

このガイドでは、W\&Bを自分のPythonライブラリに統合して、強力な実験追跡、GPUおよびシステムモニタリング、モデルチェックポイントなどを自分のライブラリに取り入れるためのベストプラクティスを提供します。

<Note>
  W\&Bの使い方をまだ学んでいる場合は、さらに読み進める前に、これらのドキュメントにある他のW\&Bガイド（例えば[実験追跡](/ja/guides/track)）を探索することをお勧めします。
</Note>

以下では、単一のPythonトレーニングスクリプトやJupyterノートブックよりも複雑なコードベースで作業している場合のベストなヒントとベストプラクティスについて説明します。取り上げるトピックは以下の通りです：

* セットアップ要件
* ユーザーログイン
* wandb Runの開始
* Run Configの定義
* W\&Bへのログ記録
* 分散トレーニング
* モデルチェックポイントなど
* ハイパーパラメータチューニング
* 高度なインテグレーション

### セットアップ要件[​](#setup-requirements "Direct link to Setup requirements")

始める前に、ライブラリの依存関係にW\&Bを必須とするかどうかを決定してください：

#### インストール時にW\&Bを必須にする[​](#require-wb-on-installation "Direct link to Require W\&B On Installation")

W\&B Pythonライブラリ（`wandb`）を依存関係ファイルに追加します。例えば、`requirements.txt`ファイル内に

```
torch==1.8.0 ...wandb==0.13.*
```

#### インストール時にW\&Bをオプションにする[​](#make-wb-optional-on-installation "Direct link to Make W\&B optional On Installation")

W\&B SDK（`wandb`）をオプションにする方法は2つあります：

A. ユーザーが手動でインストールせずに`wandb`機能を使用しようとした場合にエラーを発生させ、適切なエラーメッセージを表示します：

```
try:     import wandb except ImportError:     raise ImportError(        “You are trying to use wandb which is not currently installed”        “Please install it using pip install wandb”    ) 
```

B. `wandb`をオプションの依存関係として`pyproject.toml`ファイルに追加します（Pythonパッケージを構築している場合）。

```
[project]name = "my_awesome_lib"version = "0.1.0"dependencies = [    "torch",    "sklearn"][project.optional-dependencies]dev = [    "wandb"]
```

### ユーザーログイン[​](#user-login "Direct link to User Login")

ユーザーがW\&Bにログインするには、いくつかの方法があります：

* Bash
* ノートブック
* 環境変数

ターミナルでbashコマンドを使用してW\&Bにログインする

```
wandb login $MY_WANDB_KEY
```

JupyterまたはColabノートブックの場合、次のようにW\&Bにログインします

```
import wandbwandb.login
```

APIキーのために[W\&B環境変数](/guides/track/environment-variables)を設定する

```
export WANDB_API_KEY=$YOUR_API_KEY
```

または

```
os.environ['WANDB_API_KEY'] = "abc123..."
```

ユーザーが上記のステップに従わずに初めてwandbを使用する場合、スクリプトが`wandb.init`

### wandb Runの開始[​](#starting-a-wandb-run "Direct link to Starting A wandb Run")

W\&B Runは、W\&Bによってログに記録される計算の単位です。通常、1つのトレーニング実験ごとに1つのW\&B Runを関連付けます。

コード内でW\&Bを初期化してRunを開始するには：

```
wandb.init()
```

オプションでプロジェクトの名前を指定することもできますし、ユーザーに`wandb_project`などのパラメータをコードで設定させることもできます。また、entityパラメータにはユーザー名またはチーム名（例：`wandb_entity`）を指定します：

```
wandb.init(project=wandb_project, entity=wandb_entity)
```

#### どこに`wandb.init`を配置するか？[​](#where-to-place-wandbinit "Direct link to where-to-place-wandbinit")

ライブラリはできるだけ早くW\&B Runを作成する必要があります。これは、エラーメッセージを含むコンソールの出力がすべてW\&B Runの一部としてログに記録されるためです。これによりデバッグが容易になります。

#### ライブラリを`wandb`をオプションとして実行する[​](#run-the-library-with-wandb-as-optional "Direct link to run-the-library-with-wandb-as-optional")

ユーザーがライブラリを使用する際に`wandb`をオプションにしたい場合は、次のいずれかの方法を使用できます：

* 次のような`wandb`フラグを定義する：

* Python

* Bash

```
trainer = my_trainer(..., use_wandb=True)
```

```
python train.py ... --use-wandb
```

* または、`wandb`を`disabled`に設定する`wandb.init`

* Python

* Bash

```
wandb.init(mode=“disabled”)
```

```
export WANDB_MODE=disabled
```

または

```
wandb disabled
```

* または、`wandb`をオフラインに設定する - これでも`wandb`は実行されますが、インターネット経由でW\&Bと通信しようとはしません

* 環境変数

* Bash

```
export WANDB_MODE=offline
```

または

```
os.environ['WANDB_MODE'] = 'offline'
```

```
wandb offline
```

### wandb Run Configの定義[​](#defining-a-wandb-run-config "Direct link to Defining A wandb Run Config")

W\&B Runを作成するときに`wandb`実行構成を使用して、モデル、データセットなどに関するメタデータを提供できます。この情報を使用して、異なる実験を比較し、主な違いを素早く理解することができます。

![W\&amp;B Runs table](/assets/images/integrations_add_any_lib_runs_page-127a613c3a210a9349645672feeee09e.png)

ログに記録できる一般的な構成パラメータには以下が含まれます：

* モデル名、バージョン、アーキテクチャパラメータなど
* データセット名、バージョン、トレーニング/検証例の数など
* 学習率、バッチサイズ、オプティマイザなどのトレーニングパラメータ

以下のコードスニペットは、構成をログに記録する方法を示しています：

```
config = {“batch_size”:32, …}wandb.init(…, config=config)
```

#### wandb configの更新[​](#updating-the-wandb-config "Direct link to Updating The wandb config")

構成を更新するには`wandb.config.update`を使用します。構成辞書の更新は、パラメータが辞書の定義後に取得される場合に便利です。例えば、モデルのインスタンス化後にモデルのパラメータを追加したい場合などです。

```
wandb.config.update({“model_parameters” = 3500})
```

構成ファイルの定義方法の詳細については、[wandb.configで実験を構成する](/guides/track/config)

### W\&Bへのログ記録[​](#logging-to-wb "Direct link to Logging To W\&B")

#### メトリクスのログ記録[​](#log-metrics "Direct link to Log Metrics")

キー値がメトリクスの名前である辞書を作成します。この辞書オブジェクトを[`wandb.log`](/guides/track/log)に渡します：

```
for epoch in range(NUM_EPOCHS):    for input, ground_truth in data:         prediction = model(input)         loss = loss_fn(prediction, ground_truth)         metrics = { “loss”: loss }         wandb.log(metrics)
```

多くのメトリクスがある場合、メトリクス名にプレフィックスを使用することで、UIで自動的にグループ化することができます。例えば`train/...`や`val/...`などです。これにより、W\&B Workspaceにトレーニングメトリクスと検証メトリクス、または分離したい他のメトリクスタイプのための別々のセクションが作成されます。

```
metrics = {    “train/loss”: 0.4,    “train/learning_rate”: 0.4,    “val/loss”: 0.5,     “val/accuracy”: 0.7}wandb.log(metrics)
```

![A W\&amp;B Workspace with 2 separate sections](/assets/images/integrations_add_any_lib_log-e57d04e8733479e53f5955170ed0ed03.png)

についての詳細は、`wandb.log`を参照してください[wandb.logでデータをログに記録する](/guides/track/log)

#### x軸のずれを防ぐ[​](#preventing-x-axis-misalignments "Direct link to Preventing x-axis Misalignments")

同じトレーニングステップで複数回`wandb.log`を呼び出す必要がある場合があります。wandb SDKには、`wandb.log`が呼び出されるたびにインクリメントされる独自の内部ステップカウンターがあります。これは、wandbログカウンターがトレーニングループ内のトレーニングステップと一致しない可能性があることを意味します。

以下の例の最初のパスでは、`wandb`の内部`train/loss`ステップは0になり、`wandb`の内部`eval/loss`ステップは1になります。次のパスでは、`train/loss`は2になり、`eval/loss`wandbステップは3になります。

```
for input, ground_truth in data:    ...    wandb.log(“train/loss”: 0.1)      wandb.log(“eval/loss”: 0.2)
```

これを避けるために、x軸のステップを明示的に定義することをお勧めします。`wandb.define_metric`でx軸を定義でき、`wandb.init`が呼び出された後に一度だけ行う必要があります：

```
wandb.init(...)wandb.define_metric("*", step_metric="global_step")
```

グロブパターン「\*」は、すべてのメトリクスがチャートのx軸として「global\_step」を使用することを意味します。特定のメトリクスのみを「global\_step」に対してログに記録したい場合は、代わりにそれらを指定できます：

```
wandb.define_metric("train/loss", step_metric="global_step")
```

これで呼び出しが完了したら`wandb.define_metric`、メトリクスと`step_metric`、「global\_step」を`wandb.log`を呼び出すたびにログに記録するだけです：

```
for step, (input, ground_truth) in enumerate(data):    ...    wandb.log({“global_step”: step, “train/loss”: 0.1})    wandb.log({“global_step”: step, “eval/loss”: 0.2})
```

独立したステップ変数にアクセスできない場合、例えば検証ループ中に「global\_step」が利用できない場合、wandbは自動的に「global\_step」の前回ログに記録された値を使用します。この場合、必要なときに定義されているように、メトリクスの初期値を必ずログに記録してください。

#### 画像、テーブル、テキスト、音声などをログに記録する[​](#log-images-tables-text-audio-and-more "Direct link to Log Images, Tables, Text, Audio and More")

メトリクスに加えて、プロット、ヒストグラム、テーブル、テキスト、および画像、動画、音声、3Dなどのメディアをログに記録できます。

データをログに記録する際の考慮事項には以下が含まれます：

* メトリクスをどのくらいの頻度でログに記録すべきか？オプションにすべきか？

* 視覚化に役立つデータの種類は何か？

  * 画像の場合、サンプル予測やセグメンテーションマスクなどをログに記録して、時間の経過に伴う進化を確認できます。
  * テキストの場合、後で探索するためにサンプル予測のテーブルをログに記録できます。

詳細については[wandb.logでデータをログに記録する](/guides/track/log)を参照して、メディア、オブジェクト、プロットなどのログ記録に関する完全なガイドを確認してください。

### 分散トレーニング[​](#distributed-training "Direct link to Distributed Training")

分散環境をサポートするフレームワークでは、以下のワークフローのいずれかを適応させることができます：

* どのプロセスが「メイン」プロセスかを検出し、そこでのみ`wandb`を使用します。他のプロセスから必要なデータは、まずメインプロセスにルーティングする必要があります。（このワークフローが推奨されます）。
* すべてのプロセスで`wandb`を呼び出し、すべてに同じユニークな`group`名前

詳細については[分散トレーニング実験をログに記録する](/guides/track/log/distributed-training)を参照してください

### モデルチェックポイントなどのログ記録[​](#logging-model-checkpoints-and-more "Direct link to Logging Model Checkpoints And More")

フレームワークがモデルやデータセットを使用または生成する場合、完全なトレーサビリティのためにそれらをログに記録し、W\&B Artifactsを通じてwandbがパイプライン全体を自動的に監視できるようにすることができます。

![Stored Datasets and Model Checkpoints in W\&amp;B](/assets/images/integrations_add_any_lib_dag-24b3adbe07e168c7883034e4f2790bb4.png)

Artifactsを使用する場合、ユーザーに以下を定義させることは有用ですが、必須ではありません：

* モデルチェックポイントやデータセットをログに記録する機能（オプションにしたい場合）
* 入力として使用されるアーティファクトのパス/参照（ある場合）。例えば「user/project/artifact」
* Artifactsをログに記録する頻度

#### モデルチェックポイントをログに記録する[​](#log-model-checkpoints "Direct link to Log Model Checkpoints")

モデルチェックポイントをW\&Bにログに記録できます。ユニークな`wandb`Run IDを活用して出力モデルチェックポイントに名前を付け、Run間で区別することが有用です。また、有用なメタデータを追加することもできます。さらに、以下のように各モデルにエイリアスを追加することもできます：

```
metadata = {“eval/accuracy”: 0.8, “train/steps”: 800} artifact = wandb.Artifact(                name=f”model-{wandb.run.id}”,                 metadata=metadata,                 type=”model”                ) artifact.add_dir(“output_model”) #local directory where the model weights are storedaliases = [“best”, “epoch_10”] wandb.log_artifact(artifact, aliases=aliases)
```

カスタムエイリアスの作成方法については、[カスタムエイリアスを作成する](/guides/artifacts/create-a-custom-alias)

出力Artifactsは任意の頻度（例えば、エポックごと、500ステップごとなど）でログに記録でき、自動的にバージョン管理されます。

#### 事前訓練済みモデルやデータセットをログに記録して追跡する[​](#log-and-track-pre-trained-models-or-datasets "Direct link to Log And Track Pre-trained Models Or Datasets")

トレーニングへの入力として使用されるアーティファクト（事前訓練済みモデルやデータセットなど）をログに記録できます。以下のスニペットは、アーティファクトをログに記録し、上のグラフに示されているように進行中のRunへの入力として追加する方法を示しています。

```
artifact_input_data = wandb.Artifact(name=”flowers”, type=”dataset”)artifact_input_data.add_file(“flowers.npy”)wandb.use_artifact(artifact_input_data)
```

#### W\&B Artifactをダウンロードする[​](#download-a-wb-artifact "Direct link to Download A W\&B Artifact")

Artifact（データセット、モデルなど）を再利用し、`wandb`がローカルにコピーをダウンロードします（そしてキャッシュします）：

```
artifact = wandb.run.use_artifact(“user/project/artifact:latest”)local_path = artifact.download(“./tmp”)
```

ArtifactsはW\&BのArtifactsセクションで見つけることができ、自動的に生成されたエイリアス（「latest」、「v2」、「v3」）または手動でログ記録時に指定したエイリアス（「best\_accuracy」など）で参照できます。

Artifactをダウンロードするために`wandb`runを作成せずに（`wandb.init`を通じて）、例えば分散環境や単純な推論のために、代わりに[wandb API](/ref/python/public-api)でアーティファクトを参照できます：

```
artifact = wandb.Api().artifact(“user/project/artifact:latest”)local_path = artifact.download()
```

詳細については、[Artifactsのダウンロードと使用](/guides/artifacts/download-and-use-an-artifact)を参照してください。

### ハイパーパラメータチューニング[​](#hyper-parameter-tuning "Direct link to Hyper-parameter Tuning")

ライブラリがW\&Bハイパーパラメータチューニングを活用したい場合、[W\&B Sweeps](/guides/sweeps)もライブラリに追加できます

### 高度な統合[​](#advanced-integrations "Direct link to Advanced Integrations")

以下の統合で高度なW\&B統合がどのように見えるかを確認することもできます。ほとんどの統合はこれらほど複雑ではないことに注意してください：

* [Hugging Face Transformers `WandbCallback`](https://github.com/huggingface/transformers/blob/49629e7ba8ef68476e08b671d6fc71288c2f16f1/src/transformers/integrations.py#L639)
* [PyTorch Lightning `WandbLogger`](https://github.com/Lightning-AI/lightning/blob/18f7f2d3958fb60fcb17b4cb69594530e83c217f/src/pytorch_lightning/loggers/wandb.py#L53)
