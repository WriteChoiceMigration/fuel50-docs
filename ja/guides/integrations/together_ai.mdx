# Together AI

Together AIは、生成AIモデルの構築と微調整のためのプラットフォームで、オープンソースLLMに焦点を当て、顧客が独自のモデルを微調整してホストすることを可能にします。

<Info>
  完全なWeave `together` pythonパッケージのサポートは現在開発中です
</Info>

完全なWeaveサポートが `together` pythonパッケージで現在開発中ですが、TogetherはOpenAI SDK互換性（[ドキュメント](https://docs.together.ai/docs/openai-api-compatibility)）をサポートしており、Weaveは自動的にこれを検出して統合します。

Together APIを使用するように切り替えるには、APIキーを [Together API](https://docs.together.ai/docs/get-started#access-your-api-key) キーに変更し、`base_url` を `https://api.together.xyz/v1` に変更し、モデルを彼らの [チャットモデル](https://docs.together.ai/docs/inference-models#chat-models) のいずれかに変更するだけです。

```python
import os
import openai
import weave

# highlight-next-line
weave.init('together-weave')

system_content = "You are a travel agent. Be descriptive and helpful."
user_content = "Tell me about San Francisco"

# highlight-next-line
client = openai.OpenAI(
# highlight-next-line
    api_key=os.environ.get("TOGETHER_API_KEY"),
# highlight-next-line
    base_url="https://api.together.xyz/v1",
# highlight-next-line
)
chat_completion = client.chat.completions.create(
    model="mistralai/Mixtral-8x7B-Instruct-v0.1",
    messages=[
        {"role": "system", "content": system_content},
        {"role": "user", "content": user_content},
    ],
    temperature=0.7,
    max_tokens=1024,
)
response = chat_completion.choices[0].message.content
print("Together response:\n", response)
```

これは始めるための簡単な例ですが、より複雑なユースケースでWeaveを独自の関数と統合する方法の詳細については、[OpenAI](/ja/guides/integrations/openai#track-your-own-ops) ガイドをご覧ください。
