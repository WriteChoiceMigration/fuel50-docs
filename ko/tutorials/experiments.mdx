---
- title: 실험 추적
---

<CardGroup>
  <Card title="Colab에서 시도해보기" icon={<svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" fill="none" class="sc-dntaoT fLPWGM"><path d="M5.06541 9.08411L2.88146 6.89087C1.67664 8.09827 1 9.7343 1 11.44C1 13.1457 1.67664 14.7817 2.88146 15.9891L5.0747 13.7959C4.44978 13.1717 4.09786 12.3252 4.09612 11.4419C4.09438 10.5587 4.44295 9.71076 5.06541 9.08411Z" fill="#E8710A"></path><path d="M2.88146 6.89071L5.06541 9.08395C5.37527 8.77373 5.74324 8.52763 6.14827 8.35972C6.55331 8.1918 6.98747 8.10538 7.42594 8.10538C7.8644 8.10538 8.29856 8.1918 8.7036 8.35972C9.10864 8.52763 9.4766 8.77373 9.78646 9.08395L11.3756 6.36098L11.2827 6.28663C10.0431 5.36184 8.51219 4.91398 6.96964 5.02489C5.42709 5.13581 3.97596 5.79809 2.88146 6.89071Z" fill="#F9AB00"></path><path d="M11.3849 16.5187L9.78646 13.8051C9.4766 14.1153 9.10864 14.3614 8.7036 14.5293C8.29856 14.6972 7.8644 14.7836 7.42594 14.7836C6.98747 14.7836 6.55331 14.6972 6.14827 14.5293C5.74324 14.3614 5.37527 14.1153 5.06541 13.8051L2.88146 15.9983C3.97378 17.0812 5.41759 17.7374 6.95171 17.8482C8.48582 17.959 10.0089 17.517 11.2455 16.6024L11.3478 16.5187" fill="#F9AB00"></path><path d="M11.9983 6.89075C10.7935 8.09815 10.1168 9.73418 10.1168 11.4399C10.1168 13.1456 10.7935 14.7816 11.9983 15.989L14.1915 13.7958C13.5655 13.1697 13.2138 12.3206 13.2138 11.4352C13.2138 10.5499 13.5655 9.70075 14.1915 9.0747C14.8176 8.44865 15.6667 8.09694 16.5521 8.09694C17.4374 8.09694 18.2865 8.44865 18.9126 9.0747L21.1151 6.89075C20.5169 6.29138 19.8064 5.81588 19.0242 5.49144C18.242 5.167 17.4035 5 16.5567 5C15.7099 5 14.8714 5.167 14.0892 5.49144C13.307 5.81588 12.5965 6.29138 11.9983 6.89075Z" fill="#F9AB00"></path><path d="M21.1151 6.89087L18.9312 9.08411C19.5572 9.71016 19.9089 10.5593 19.9089 11.4446C19.9089 12.33 19.5572 13.1791 18.9312 13.8052C18.3051 14.4312 17.456 14.7829 16.5706 14.7829C15.6853 14.7829 14.8362 14.4312 14.2101 13.8052L11.9983 15.9984C13.206 17.2074 14.8446 17.8871 16.5534 17.8879C17.3996 17.8884 18.2375 17.7221 19.0194 17.3987C19.8013 17.0753 20.5119 16.6011 21.1105 16.0031C21.7091 15.405 22.1841 14.695 22.5083 13.9134C22.8325 13.1318 22.9996 12.2941 23 11.4479C23.0004 10.6018 22.8342 9.76384 22.5108 8.98194C22.1874 8.20003 21.7131 7.48949 21.1151 6.89087Z" fill="#E8710A"></path></svg>} href="https://colab.research.google.com/github/wandb/examples/blob/master/colabs/intro/Intro_to_Weights_%26_Biases.ipynb" horizontal iconType="solid" />
</CardGroup>

사용 [W\&B](https://wandb.ai/site) 머신 러닝 실험 추적, 모델 체크포인팅, 팀과의 협업 등을 위해.

이 노트북에서는 간단한 PyTorch 모델을 사용하여 머신 러닝 실험을 생성하고 추적할 것입니다. 노트북을 마치면 팀의 다른 구성원과 공유하고 사용자 지정할 수 있는 대화형 프로젝트 대시보드가 생성됩니다. [여기에서 예제 대시보드 보기](https://wandb.ai/wandb/wandb_example).

## 사전 요구 사항

W\&B Python SDK를 설치하고 로그인하세요:

```
!pip install wandb -qU
```

```py
# Log in to your W&B account
import wandb
import random
import math

# Use wandb-core, temporary for wandb's new backend
wandb.require("core")
```

```
wandb.login()
```

## W\&B로 머신 러닝 실험 시뮬레이션 및 추적

머신 러닝 실험을 생성, 추적 및 시각화합니다. 이를 위해:

1. 초기화 [W\&B run](/guides/runs) 및 추적하려는 하이퍼파라미터를 전달하세요.
2. 훈련 루프 내에서 정확도 및 손실과 같은 메트릭을 기록하세요.

```py
import random
import math

# Launch 5 simulated experiments
total_runs = 5
for run in range(total_runs):
  # 1️. Start a new run to track this script
  wandb.init(
      # Set the project where this run will be logged
      project="basic-intro",
      # We pass a run name (otherwise it’ll be randomly assigned, like sunshine-lollypop-10)
      name=f"experiment_{run}",
      # Track hyperparameters and run metadata
      config={
      "learning_rate": 0.02,
      "architecture": "CNN",
      "dataset": "CIFAR-100",
      "epochs": 10,
      })

  # This simple block simulates a training loop logging metrics
  epochs = 10
  offset = random.random() / 5
  for epoch in range(2, epochs):
      acc = 1 - 2 ** -epoch - random.random() / epoch - offset
      loss = 2 ** -epoch + random.random() / epoch + offset

      # 2️. Log metrics from your script to W&B
      wandb.log({"acc": acc, "loss": loss})

  # Mark the run as finished
  wandb.finish()
```

W\&B 프로젝트에서 머신 러닝 성능을 확인하세요. 이전 셀에서 인쇄된 URL 링크를 복사하여 붙여넣으세요. URL은 그래프가 표시된 대시보드가 포함된 W\&B 프로젝트로 리디렉션됩니다.

다음 이미지는 대시보드가 어떻게 보일 수 있는지 보여줍니다:

<Frame>
  ![](/images/tutorials/assets/images/experiments-1-aa7a86df71d0bf080e2240c416273c70.png)
</Frame>

이제 W\&B를 가상 머신 러닝 훈련 루프에 통합하는 방법을 알았으니, 기본 PyTorch 신경망을 사용하여 머신 러닝 실험을 추적해 보겠습니다. 다음 코드는 모델 체크포인트를 W\&B에 업로드하여 조직 내 다른 팀과 공유할 수 있습니다.

## PyTorch를 사용하여 머신 러닝 실험 추적

다음 코드 셀은 간단한 MNIST 분류기를 정의하고 훈련합니다. 훈련 중에 W\&B가 URL을 출력하는 것을 볼 수 있습니다. 프로젝트 페이지 링크를 클릭하여 결과가 W\&B 프로젝트에 실시간으로 스트리밍되는 것을 확인하세요.

W\&B runs는 자동으로 [metrics](/guides/runs#workspace-tab), [system information](/guides/runs#system-tab), [hyperparameters](/guides/runs#overview-tab), [terminal output](/guides/runs#logs-tab)을 기록하고 [interactive table](/guides/tables)에서 모델 입력 및 출력을 볼 수 있습니다.

### PyTorch Dataloader 설정

다음 셀은 머신 러닝 모델을 훈련하는 데 필요한 몇 가지 유용한 함수를 정의합니다. 이 함수들은 W\&B에만 국한된 것이 아니므로 여기서 자세히 다루지 않겠습니다. [forward and backward training loop](https://pytorch.org/tutorials/beginner/nn_tutorial.html), [PyTorch DataLoaders](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)를 사용하여 훈련 데이터를 로드하는 방법, 그리고 [`torch.nn.Sequential` Class](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html)를 사용하여 PyTorch 모델을 정의하는 방법에 대한 자세한 내용은 PyTorch 문서를 참조하세요.

```py
# @title
import torch, torchvision
import torch.nn as nn
from torchvision.datasets import MNIST
import torchvision.transforms as T

MNIST.mirrors = [
    mirror for mirror in MNIST.mirrors if "http://yann.lecun.com/" not in mirror
]

device = "cuda:0" if torch.cuda.is_available() else "cpu"


def get_dataloader(is_train, batch_size, slice=5):
    "Get a training dataloader"
    full_dataset = MNIST(
        root=".", train=is_train, transform=T.ToTensor(), download=True
    )
    sub_dataset = torch.utils.data.Subset(
        full_dataset, indices=range(0, len(full_dataset), slice)
    )
    loader = torch.utils.data.DataLoader(
        dataset=sub_dataset,
        batch_size=batch_size,
        shuffle=True if is_train else False,
        pin_memory=True,
        num_workers=2,
    )
    return loader


def get_model(dropout):
    "A simple model"
    model = nn.Sequential(
        nn.Flatten(),
        nn.Linear(28 * 28, 256),
        nn.BatchNorm1d(256),
        nn.ReLU(),
        nn.Dropout(dropout),
        nn.Linear(256, 10),
    ).to(device)
    return model


def validate_model(model, valid_dl, loss_func, log_images=False, batch_idx=0):
    "Compute performance of the model on the validation dataset and log a wandb.Table"
    model.eval()
    val_loss = 0.0
    with torch.inference_mode():
        correct = 0
        for i, (images, labels) in enumerate(valid_dl):
            images, labels = images.to(device), labels.to(device)

            # Forward pass ➡
            outputs = model(images)
            val_loss += loss_func(outputs, labels) * labels.size(0)

            # Compute accuracy and accumulate
            _, predicted = torch.max(outputs.data, 1)
            correct += (predicted == labels).sum().item()

            # Log one batch of images to the dashboard, always same batch_idx.
            if i == batch_idx and log_images:
                log_image_table(images, predicted, labels, outputs.softmax(dim=1))
    return val_loss / len(valid_dl.dataset), correct / len(valid_dl.dataset)
```

### 예측값과 실제값을 비교하는 테이블 생성

다음 셀은 W\&B에만 해당되므로 살펴보겠습니다.

이 셀에서는 `log_image_table` 함수를 정의합니다. 기술적으로는 선택 사항이지만, 이 함수는 W\&B Table 객체를 생성합니다. 이 테이블 객체를 사용하여 모델이 각 이미지에 대해 예측한 내용을 보여주는 테이블을 만들 것입니다.

더 구체적으로, 각 행은 모델에 입력된 이미지와 예측값 및 실제값(레이블)으로 구성됩니다.

```py
def log_image_table(images, predicted, labels, probs):
    "Log a wandb.Table with (img, pred, target, scores)"
    # Create a wandb Table to log images, labels and predictions to
    table = wandb.Table(
        columns=["image", "pred", "target"] + [f"score_{i}" for i in range(10)]
    )
    for img, pred, targ, prob in zip(
        images.to("cpu"), predicted.to("cpu"), labels.to("cpu"), probs.to("cpu")
    ):
        table.add_data(wandb.Image(img[0].numpy() * 255), pred, targ, *prob.numpy())
    wandb.log({"predictions_table": table}, commit=False)
```

### 모델 훈련 및 체크포인트 업로드

다음 코드는 모델을 훈련하고 모델 체크포인트를 프로젝트에 저장합니다. 모델 체크포인트를 평소와 같이 사용하여 훈련 중 모델 성능을 평가하세요.

W\&B는 저장된 모델과 모델 체크포인트를 팀이나 조직의 다른 구성원과 쉽게 공유할 수 있게 해줍니다. 모델 및 모델 체크포인트를 팀 외부 구성원과 공유하는 방법을 알아보려면 [W\&B Registry](/guides/registry)를 참조하세요.

```py
# Launch 3 experiments, trying different dropout rates
for _ in range(3):
    # initialise a wandb run
    wandb.init(
        project="pytorch-intro",
        config={
            "epochs": 5,
            "batch_size": 128,
            "lr": 1e-3,
            "dropout": random.uniform(0.01, 0.80),
        },
    )

    # Copy your config
    config = wandb.config

    # Get the data
    train_dl = get_dataloader(is_train=True, batch_size=config.batch_size)
    valid_dl = get_dataloader(is_train=False, batch_size=2 * config.batch_size)
    n_steps_per_epoch = math.ceil(len(train_dl.dataset) / config.batch_size)

    # A simple MLP model
    model = get_model(config.dropout)

    # Make the loss and optimizer
    loss_func = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)

    # Training
    example_ct = 0
    step_ct = 0
    for epoch in range(config.epochs):
        model.train()
        for step, (images, labels) in enumerate(train_dl):
            images, labels = images.to(device), labels.to(device)

            outputs = model(images)
            train_loss = loss_func(outputs, labels)
            optimizer.zero_grad()
            train_loss.backward()
            optimizer.step()

            example_ct += len(images)
            metrics = {
                "train/train_loss": train_loss,
                "train/epoch": (step + 1 + (n_steps_per_epoch * epoch))
                / n_steps_per_epoch,
                "train/example_ct": example_ct,
            }

            if step + 1 < n_steps_per_epoch:
                # Log train metrics to wandb
                wandb.log(metrics)

            step_ct += 1

        val_loss, accuracy = validate_model(
            model, valid_dl, loss_func, log_images=(epoch == (config.epochs - 1))
        )

        # Log train and validation metrics to wandb
        val_metrics = {"val/val_loss": val_loss, "val/val_accuracy": accuracy}
        wandb.log({**metrics, **val_metrics})

        # Save the model checkpoint to wandb
        torch.save(model, "my_model.pt")
        wandb.log_model(
            "./my_model.pt",
            "my_mnist_model",
            aliases=[f"epoch-{epoch+1}_dropout-{round(wandb.config.dropout, 4)}"],
        )

        print(
            f"Epoch: {epoch+1}, Train Loss: {train_loss:.3f}, Valid Loss: {val_loss:3f}, Accuracy: {accuracy:.2f}"
        )

    # If you had a test set, this is how you could log it as a Summary metric
    wandb.summary["test_accuracy"] = 0.8

    # Close your wandb run
    wandb.finish()
```

이제 W\&B를 사용하여 첫 번째 모델을 훈련했습니다. 위의 링크 중 하나를 클릭하여 메트릭을 확인하고 W\&B 앱 UI의 Artifacts 탭에서 저장된 모델 체크포인트를 확인하세요

## (선택 사항) W\&B Alert 설정

생성 [W\&B Alerts](/guides/runs/alert/) Python 코드에서 Slack이나 이메일로 알림을 보내기 위해.

Python 코드에서 트리거되는 Slack 또는 이메일 알림을 처음 보내려면 다음 2단계를 따르세요:

1. W\&B [User Settings](https://wandb.ai/settings)
2. 추가 `wandb.alert()` 코드에. 예를 들어:

```
wandb.alert(title="Low accuracy", text=f"Accuracy is below the acceptable threshold")
```

다음 셀은 `wandb.alert`

```py
# Start a wandb run
wandb.init(project="pytorch-intro")

# Simulating a model training loop
acc_threshold = 0.3
for training_step in range(1000):

    # Generate a random number for accuracy
    accuracy = round(random.random() + random.random(), 3)
    print(f"Accuracy is: {accuracy}, {acc_threshold}")

    # Log accuracy to wandb
    wandb.log({"Accuracy": accuracy})

    # If the accuracy is below the threshold, fire a W&B Alert and stop the run
    if accuracy <= acc_threshold:
        # Send the wandb Alert
        wandb.alert(
            title="Low Accuracy",
            text=f"Accuracy {accuracy} at step {training_step} is below the acceptable theshold, {acc_threshold}",
        )
        print("Alert triggered")
        break

# Mark the run as finished (useful in Jupyter notebooks)
wandb.finish()
```

전체 문서는 [W\&B Alerts 여기](/guides/runs/alert)에서 찾을 수 있습니다.

## 다음 단계

다음 튜토리얼에서는 W\&B Sweeps를 사용하여 하이퍼파라미터 최적화를 수행하는 방법을 배웁니다: [PyTorch를 사용한 하이퍼파라미터 스윕](https://colab.research.google.com/github/wandb/examples/blob/master/colabs/pytorch/Organizing_Hyperparameter_Sweeps_in_PyTorch_with_W%26B.ipynb)
