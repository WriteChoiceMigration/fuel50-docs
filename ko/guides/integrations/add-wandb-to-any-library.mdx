---
- title: 모든 라이브러리에 wandb 추가하기
---

* [홈](/)
* [통합](/ko/guides/integrations)
* 어떤 라이브러리에도 wandb 추가하기

이 페이지에서

이 가이드는 W\&B를 Python 라이브러리에 통합하여 강력한 실험 추적, GPU 및 시스템 모니터링, 모델 체크포인팅 등을 자신의 라이브러리에 적용하는 모범 사례를 제공합니다.

<Note>
  W\&B 사용법을 아직 배우고 계신다면, 계속 읽기 전에 이 문서에 있는 다른 W\&B 가이드를 살펴보는 것이 좋습니다. 예를 들어 [실험 추적](/ko/guides/track) 등이 있습니다.
</Note>

아래에서는 단일 Python 훈련 스크립트나 Jupyter 노트북보다 더 복잡한 코드베이스로 작업할 때 유용한 팁과 모범 사례를 다룹니다. 다루는 주제는 다음과 같습니다:

* 설정 요구사항
* 사용자 로그인
* wandb Run 시작하기
* Run 구성 정의하기
* W\&B에 로깅하기
* 분산 훈련
* 모델 체크포인팅 및 기타
* 하이퍼파라미터 튜닝
* 고급 통합

### 설정 요구사항[​](#setup-requirements "Direct link to Setup requirements")

시작하기 전에 라이브러리 종속성에 W\&B를 필수로 할지 여부를 결정하세요:

#### 설치 시 W\&B 필수로 지정[​](#require-wb-on-installation "Direct link to Require W\&B On Installation")

W\&B Python 라이브러리(`wandb`)를 종속성 파일에 추가하세요. 예를 들어, `requirements.txt` 파일에 추가

```
torch==1.8.0 ...wandb==0.13.*
```

#### 설치 시 W\&B를 선택 사항으로 지정[​](#make-wb-optional-on-installation "Direct link to Make W\&B optional On Installation")

W\&B SDK(`wandb`)를 선택 사항으로 만드는 두 가지 방법이 있습니다:

A. 사용자가 수동으로 설치하지 않고 `wandb` 기능을 사용하려고 할 때 오류를 발생시키고 적절한 오류 메시지를 표시합니다:

```
try:     import wandb except ImportError:     raise ImportError(        “You are trying to use wandb which is not currently installed”        “Please install it using pip install wandb”    ) 
```

B. `wandb`를 선택적 종속성으로 `pyproject.toml` 파일에 추가하세요(Python 패키지를 빌드하는 경우).

```
[project]name = "my_awesome_lib"version = "0.1.0"dependencies = [    "torch",    "sklearn"][project.optional-dependencies]dev = [    "wandb"]
```

### 사용자 로그인[​](#user-login "Direct link to User Login")

사용자가 W\&B에 로그인할 수 있는 몇 가지 방법이 있습니다:

* Bash
* Notebook
* 환경 변수

터미널에서 bash 명령으로 W\&B에 로그인

```
wandb login $MY_WANDB_KEY
```

Jupyter나 Colab 노트북에서는 다음과 같이 W\&B에 로그인

```
import wandbwandb.login
```

API 키를 위한 [W\&B 환경 변수](/guides/track/environment-variables) 설정

```
export WANDB_API_KEY=$YOUR_API_KEY
```

또는

```
os.environ['WANDB_API_KEY'] = "abc123..."
```

사용자가 위에 언급된 단계를 따르지 않고 wandb를 처음 사용하는 경우, 스크립트에서 `wandb.init`

### wandb Run 시작하기[​](#starting-a-wandb-run "Direct link to Starting A wandb Run")

W\&B Run은 W\&B에 의해 기록되는 계산 단위입니다. 일반적으로 훈련 실험당 하나의 W\&B Run을 연결합니다.

코드 내에서 W\&B를 초기화하고 Run을 시작하려면:

```
wandb.init()
```

선택적으로 프로젝트 이름을 제공하거나, 코드에서 `wandb_project`와 같은 매개변수를 통해 사용자가 직접 설정하도록 할 수 있으며, entity 매개변수에는 `wandb_entity`와 같은 사용자 이름이나 팀 이름을 지정할 수 있습니다:

```
wandb.init(project=wandb_project, entity=wandb_entity)
```

#### 어디에 `wandb.init`를 배치해야 할까요?[​](#where-to-place-wandbinit "Direct link to where-to-place-wandbinit")

라이브러리는 가능한 한 빨리 W\&B Run을 생성해야 합니다. 콘솔의 모든 출력(오류 메시지 포함)이 W\&B Run의 일부로 기록되기 때문에 디버깅이 더 쉬워집니다.

#### 라이브러리를 `wandb`를 선택 사항으로 실행[​](#run-the-library-with-wandb-as-optional "Direct link to run-the-library-with-wandb-as-optional")

사용자가 라이브러리를 사용할 때 `wandb`를 선택 사항으로 만들고 싶다면 다음과 같이 할 수 있습니다:

* 다음과 같은 `wandb` 플래그를 정의합니다:

* Python

* Bash

```
trainer = my_trainer(..., use_wandb=True)
```

```
python train.py ... --use-wandb
```

* 또는, `wandb`를 `disabled`로 설정합니다 `wandb.init`

* Python

* Bash

```
wandb.init(mode=“disabled”)
```

```
export WANDB_MODE=disabled
```

또는

```
wandb disabled
```

* 또는, `wandb`를 오프라인으로 설정합니다 - 이렇게 해도 `wandb`는 여전히 실행되지만 인터넷을 통해 W\&B와 통신하지는 않습니다

* 환경 변수

* Bash

```
export WANDB_MODE=offline
```

또는

```
os.environ['WANDB_MODE'] = 'offline'
```

```
wandb offline
```

### wandb Run 구성 정의하기[​](#defining-a-wandb-run-config "Direct link to Defining A wandb Run Config")

W\&B Run을 생성할 때 `wandb` 실행 구성을 통해 모델, 데이터셋 등에 대한 메타데이터를 제공할 수 있습니다. 이 정보를 사용하여 다양한 실험을 비교하고 주요 차이점을 빠르게 이해할 수 있습니다.

![W\&amp;B Runs table](/assets/images/integrations_add_any_lib_runs_page-127a613c3a210a9349645672feeee09e.png)

기록할 수 있는 일반적인 구성 매개변수는 다음과 같습니다:

* 모델 이름, 버전, 아키텍처 매개변수 등
* 데이터셋 이름, 버전, 훈련/검증 예제 수 등
* 학습률, 배치 크기, 옵티마이저 등의 훈련 매개변수

다음 코드 스니펫은 구성을 로깅하는 방법을 보여줍니다:

```
config = {“batch_size”:32, …}wandb.init(…, config=config)
```

#### wandb 구성 업데이트하기[​](#updating-the-wandb-config "Direct link to Updating The wandb config")

구성을 업데이트하려면 `wandb.config.update`를 사용하세요. 구성 사전을 업데이트하는 것은 사전이 정의된 후에 매개변수를 얻을 때 유용합니다. 예를 들어 모델이 인스턴스화된 후 모델의 매개변수를 추가하고 싶을 수 있습니다.

```
wandb.config.update({“model_parameters” = 3500})
```

구성 파일 정의 방법에 대한 자세한 내용은 [wandb.config로 실험 구성하기](/guides/track/config)

### W\&B에 로깅하기[​](#logging-to-wb "Direct link to Logging To W\&B")

#### 메트릭 로깅[​](#log-metrics "Direct link to Log Metrics")

키 값이 메트릭 이름인 사전을 만듭니다. 이 사전 객체를 [`wandb.log`](/guides/track/log)에 전달합니다:

```
for epoch in range(NUM_EPOCHS):    for input, ground_truth in data:         prediction = model(input)         loss = loss_fn(prediction, ground_truth)         metrics = { “loss”: loss }         wandb.log(metrics)
```

메트릭이 많은 경우, 메트릭 이름에 접두사를 사용하여 UI에서 자동으로 그룹화할 수 있습니다. 예를 들어 `train/...`와 `val/...` 이렇게 하면 W\&B 작업 공간에서 훈련 및 검증 메트릭 또는 분리하고 싶은 다른 메트릭 유형에 대한 별도의 섹션이 생성됩니다.

```
metrics = {    “train/loss”: 0.4,    “train/learning_rate”: 0.4,    “val/loss”: 0.5,     “val/accuracy”: 0.7}wandb.log(metrics)
```

![A W\&amp;B Workspace with 2 separate sections](/assets/images/integrations_add_any_lib_log-e57d04e8733479e53f5955170ed0ed03.png)

에 대한 자세한 내용은 `wandb.log`를 참조하세요 [wandb.log로 데이터 로깅하기](/guides/track/log)

#### x축 불일치 방지[​](#preventing-x-axis-misalignments "Direct link to Preventing x-axis Misalignments")

때로는 동일한 훈련 단계에서 `wandb.log`를 여러 번 호출해야 할 수도 있습니다. wandb SDK에는 `wandb.log` 호출이 이루어질 때마다 증가하는 자체 내부 단계 카운터가 있습니다. 이는 wandb 로그 카운터가 훈련 루프의 훈련 단계와 일치하지 않을 가능성이 있음을 의미합니다.

아래 예제의 첫 번째 패스에서 `wandb`의 내부 `train/loss` 단계는 0이고, `wandb`의 내부 `eval/loss` 단계는 1입니다. 다음 패스에서는 `train/loss`가 2이고, `eval/loss` wandb 단계는 3이 됩니다. 이런 식으로 계속됩니다.

```
for input, ground_truth in data:    ...    wandb.log(“train/loss”: 0.1)      wandb.log(“eval/loss”: 0.2)
```

이를 방지하기 위해 x축 단계를 명시적으로 정의하는 것이 좋습니다. `wandb.define_metric`로 x축을 정의할 수 있으며, `wandb.init`가 호출된 후 한 번만 수행하면 됩니다:

```
wandb.init(...)wandb.define_metric("*", step_metric="global_step")
```

glob 패턴 "\*"는 모든 메트릭이 차트에서 "global\_step"을 x축으로 사용한다는 것을 의미합니다. 특정 메트릭만 "global\_step"에 대해 로깅하려면 다음과 같이 지정할 수 있습니다:

```
wandb.define_metric("train/loss", step_metric="global_step")
```

이제 다음을 호출했으니`wandb.define_metric`, 메트릭과 함께`step_metric`, "global\_step"을 매번`wandb.log`:

```
for step, (input, ground_truth) in enumerate(data):    ...    wandb.log({“global_step”: step, “train/loss”: 0.1})    wandb.log({“global_step”: step, “eval/loss”: 0.2})
```

독립적인 스텝 변수에 접근할 수 없는 경우, 예를 들어 검증 루프 중에 "global\_step"을 사용할 수 없는 경우, wandb는 이전에 로깅된 "global\_step" 값을 자동으로 사용합니다. 이 경우, 필요할 때 정의되어 있도록 메트릭의 초기 값을 로깅해야 합니다.

#### 이미지, 테이블, 텍스트, 오디오 등 로깅하기[​](#log-images-tables-text-audio-and-more "Direct link to Log Images, Tables, Text, Audio and More")

메트릭 외에도 플롯, 히스토그램, 테이블, 텍스트 및 이미지, 비디오, 오디오, 3D 등의 미디어를 로깅할 수 있습니다.

데이터를 로깅할 때 고려해야 할 사항은 다음과 같습니다:

* 메트릭을 얼마나 자주 로깅해야 하나요? 선택적으로 해야 하나요?

* 시각화에 도움이 될 수 있는 데이터 유형은 무엇인가요?

  * 이미지의 경우, 시간에 따른 변화를 확인하기 위해 샘플 예측, 세그멘테이션 마스크 등을 로깅할 수 있습니다.
  * 텍스트의 경우, 나중에 탐색할 수 있도록 샘플 예측 테이블을 로깅할 수 있습니다.

다음을 참조하세요[wandb.log로 데이터 로깅하기](/guides/track/log) 미디어, 객체, 플롯 등을 로깅하는 전체 가이드를 확인하세요.

### 분산 훈련[​](#distributed-training "Direct link to Distributed Training")

분산 환경을 지원하는 프레임워크의 경우, 다음 워크플로우 중 하나를 적용할 수 있습니다:

* "메인" 프로세스를 감지하고 해당 프로세스에서만`wandb`를 사용합니다. 다른 프로세스에서 필요한 데이터는 먼저 메인 프로세스로 라우팅되어야 합니다. (이 워크플로우가 권장됩니다).
* 모든 프로세스에서`wandb`를 호출하고 모두 동일한 고유한`group`name

다음을 참조하세요[분산 훈련 실험 로깅하기](/guides/track/log/distributed-training) 자세한 내용은 여기를 참조하세요

### 모델 체크포인트 및 기타 로깅하기[​](#logging-model-checkpoints-and-more "Direct link to Logging Model Checkpoints And More")

프레임워크가 모델이나 데이터셋을 사용하거나 생성하는 경우, 전체 추적을 위해 이를 로깅하고 W\&B Artifacts를 통해 wandb가 전체 파이프라인을 자동으로 모니터링하도록 할 수 있습니다.

![Stored Datasets and Model Checkpoints in W\&amp;B](/assets/images/integrations_add_any_lib_dag-24b3adbe07e168c7883034e4f2790bb4.png)

Artifacts를 사용할 때, 사용자가 다음을 정의할 수 있도록 하는 것이 유용할 수 있지만 필수는 아닙니다:

* 모델 체크포인트나 데이터셋을 로깅하는 기능(선택적으로 만들고 싶은 경우)
* 입력으로 사용되는 아티팩트의 경로/참조(있는 경우). 예: "user/project/artifact"
* Artifacts 로깅 빈도

#### 모델 체크포인트 로깅하기[​](#log-model-checkpoints "Direct link to Log Model Checkpoints")

모델 체크포인트를 W\&B에 로깅할 수 있습니다. 고유한`wandb`Run ID를 활용하여 출력 모델 체크포인트의 이름을 지정하면 Run 간에 구분하는 데 유용합니다. 또한 유용한 메타데이터를 추가할 수 있습니다. 아래와 같이 각 모델에 별칭을 추가할 수도 있습니다:

```
metadata = {“eval/accuracy”: 0.8, “train/steps”: 800} artifact = wandb.Artifact(                name=f”model-{wandb.run.id}”,                 metadata=metadata,                 type=”model”                ) artifact.add_dir(“output_model”) #local directory where the model weights are storedaliases = [“best”, “epoch_10”] wandb.log_artifact(artifact, aliases=aliases)
```

사용자 정의 별칭을 만드는 방법에 대한 정보는 다음을 참조하세요[사용자 정의 별칭 만들기](/guides/artifacts/create-a-custom-alias)

출력 Artifacts를 원하는 빈도(예: 매 에폭, 500 스텝마다 등)로 로깅할 수 있으며 자동으로 버전 관리됩니다.

#### 사전 훈련된 모델 또는 데이터셋 로깅 및 추적하기[​](#log-and-track-pre-trained-models-or-datasets "Direct link to Log And Track Pre-trained Models Or Datasets")

사전 훈련된 모델이나 데이터셋과 같이 훈련 입력으로 사용되는 아티팩트를 로깅할 수 있습니다. 다음 코드 스니펫은 아티팩트를 로깅하고 위 그래프에 표시된 대로 진행 중인 Run에 입력으로 추가하는 방법을 보여줍니다.

```
artifact_input_data = wandb.Artifact(name=”flowers”, type=”dataset”)artifact_input_data.add_file(“flowers.npy”)wandb.use_artifact(artifact_input_data)
```

#### W\&B 아티팩트 다운로드하기[​](#download-a-wb-artifact "Direct link to Download A W\&B Artifact")

아티팩트(데이터셋, 모델...)를 재사용하면`wandb`가 로컬에 복사본을 다운로드합니다(그리고 캐시합니다):

```
artifact = wandb.run.use_artifact(“user/project/artifact:latest”)local_path = artifact.download(“./tmp”)
```

아티팩트는 W\&B의 Artifacts 섹션에서 찾을 수 있으며, 자동으로 생성된 별칭("latest", "v2", "v3") 또는 로깅 시 수동으로 지정한 별칭("best\_accuracy"...)으로 참조할 수 있습니다.

아티팩트를`wandb`run을 생성하지 않고 다운로드하려면(`wandb.init`를 통해), 예를 들어 분산 환경이나 간단한 추론을 위해[wandb API](/ref/python/public-api):

```
artifact = wandb.Api().artifact(“user/project/artifact:latest”)local_path = artifact.download()
```

자세한 내용은 다음을 참조하세요[아티팩트 다운로드 및 사용하기](/guides/artifacts/download-and-use-an-artifact).

### 하이퍼파라미터 튜닝[​](#hyper-parameter-tuning "Direct link to Hyper-parameter Tuning")

라이브러리에서 W\&B 하이퍼파라미터 튜닝을 활용하려면,[W\&B Sweeps](/guides/sweeps)도 라이브러리에 추가할 수 있습니다

### 고급 통합[​](#advanced-integrations "Direct link to Advanced Integrations")

다음 통합에서 고급 W\&B 통합이 어떻게 보이는지 확인할 수 있습니다. 대부분의 통합은 이처럼 복잡하지 않을 것입니다:

* [Hugging Face Transformers `WandbCallback`](https://github.com/huggingface/transformers/blob/49629e7ba8ef68476e08b671d6fc71288c2f16f1/src/transformers/integrations.py#L639)
* [PyTorch Lightning `WandbLogger`](https://github.com/Lightning-AI/lightning/blob/18f7f2d3958fb60fcb17b4cb69594530e83c217f/src/pytorch_lightning/loggers/wandb.py#L53)
