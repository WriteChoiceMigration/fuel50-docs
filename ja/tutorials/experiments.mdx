---
- title: 実験を追跡する
---

<CardGroup>
  <Card title="Colabで試す" icon={<svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" fill="none" class="sc-dntaoT fLPWGM"><path d="M5.06541 9.08411L2.88146 6.89087C1.67664 8.09827 1 9.7343 1 11.44C1 13.1457 1.67664 14.7817 2.88146 15.9891L5.0747 13.7959C4.44978 13.1717 4.09786 12.3252 4.09612 11.4419C4.09438 10.5587 4.44295 9.71076 5.06541 9.08411Z" fill="#E8710A"></path><path d="M2.88146 6.89071L5.06541 9.08395C5.37527 8.77373 5.74324 8.52763 6.14827 8.35972C6.55331 8.1918 6.98747 8.10538 7.42594 8.10538C7.8644 8.10538 8.29856 8.1918 8.7036 8.35972C9.10864 8.52763 9.4766 8.77373 9.78646 9.08395L11.3756 6.36098L11.2827 6.28663C10.0431 5.36184 8.51219 4.91398 6.96964 5.02489C5.42709 5.13581 3.97596 5.79809 2.88146 6.89071Z" fill="#F9AB00"></path><path d="M11.3849 16.5187L9.78646 13.8051C9.4766 14.1153 9.10864 14.3614 8.7036 14.5293C8.29856 14.6972 7.8644 14.7836 7.42594 14.7836C6.98747 14.7836 6.55331 14.6972 6.14827 14.5293C5.74324 14.3614 5.37527 14.1153 5.06541 13.8051L2.88146 15.9983C3.97378 17.0812 5.41759 17.7374 6.95171 17.8482C8.48582 17.959 10.0089 17.517 11.2455 16.6024L11.3478 16.5187" fill="#F9AB00"></path><path d="M11.9983 6.89075C10.7935 8.09815 10.1168 9.73418 10.1168 11.4399C10.1168 13.1456 10.7935 14.7816 11.9983 15.989L14.1915 13.7958C13.5655 13.1697 13.2138 12.3206 13.2138 11.4352C13.2138 10.5499 13.5655 9.70075 14.1915 9.0747C14.8176 8.44865 15.6667 8.09694 16.5521 8.09694C17.4374 8.09694 18.2865 8.44865 18.9126 9.0747L21.1151 6.89075C20.5169 6.29138 19.8064 5.81588 19.0242 5.49144C18.242 5.167 17.4035 5 16.5567 5C15.7099 5 14.8714 5.167 14.0892 5.49144C13.307 5.81588 12.5965 6.29138 11.9983 6.89075Z" fill="#F9AB00"></path><path d="M21.1151 6.89087L18.9312 9.08411C19.5572 9.71016 19.9089 10.5593 19.9089 11.4446C19.9089 12.33 19.5572 13.1791 18.9312 13.8052C18.3051 14.4312 17.456 14.7829 16.5706 14.7829C15.6853 14.7829 14.8362 14.4312 14.2101 13.8052L11.9983 15.9984C13.206 17.2074 14.8446 17.8871 16.5534 17.8879C17.3996 17.8884 18.2375 17.7221 19.0194 17.3987C19.8013 17.0753 20.5119 16.6011 21.1105 16.0031C21.7091 15.405 22.1841 14.695 22.5083 13.9134C22.8325 13.1318 22.9996 12.2941 23 11.4479C23.0004 10.6018 22.8342 9.76384 22.5108 8.98194C22.1874 8.20003 21.7131 7.48949 21.1151 6.89087Z" fill="#E8710A"></path></svg>} href="https://colab.research.google.com/github/wandb/examples/blob/master/colabs/intro/Intro_to_Weights_%26_Biases.ipynb" horizontal iconType="solid" />
</CardGroup>

使用する[W\&B](https://wandb.ai/site)は機械学習実験の追跡、モデルのチェックポイント保存、チームとのコラボレーションなどに活用できます。

このノートブックでは、シンプルなPyTorchモデルを使用して機械学習実験を作成し追跡します。ノートブックの最後には、チームの他のメンバーと共有してカスタマイズできるインタラクティブなプロジェクトダッシュボードが完成します。[ダッシュボードの例はこちらをご覧ください](https://wandb.ai/wandb/wandb_example)。

## 前提条件

W\&B Python SDKをインストールしてログインします：

```
!pip install wandb -qU
```

```py
# Log in to your W&B account
import wandb
import random
import math

# Use wandb-core, temporary for wandb's new backend
wandb.require("core")
```

```
wandb.login()
```

## W\&Bで機械学習実験をシミュレーションして追跡する

機械学習実験を作成、追跡、視覚化します。そのためには：

1. 初期化する[W\&B run](/guides/runs)を初期化し、追跡したいハイパーパラメータを渡します。
2. トレーニングループ内で、精度や損失などのメトリクスをログに記録します。

```py
import random
import math

# Launch 5 simulated experiments
total_runs = 5
for run in range(total_runs):
  # 1️. Start a new run to track this script
  wandb.init(
      # Set the project where this run will be logged
      project="basic-intro",
      # We pass a run name (otherwise it’ll be randomly assigned, like sunshine-lollypop-10)
      name=f"experiment_{run}",
      # Track hyperparameters and run metadata
      config={
      "learning_rate": 0.02,
      "architecture": "CNN",
      "dataset": "CIFAR-100",
      "epochs": 10,
      })

  # This simple block simulates a training loop logging metrics
  epochs = 10
  offset = random.random() / 5
  for epoch in range(2, epochs):
      acc = 1 - 2 ** -epoch - random.random() / epoch - offset
      loss = 2 ** -epoch + random.random() / epoch + offset

      # 2️. Log metrics from your script to W&B
      wandb.log({"acc": acc, "loss": loss})

  # Mark the run as finished
  wandb.finish()
```

W\&Bプロジェクトで機械学習のパフォーマンスを確認します。前のセルから出力されたURLリンクをコピーして貼り付けてください。URLはW\&Bプロジェクトにリダイレクトされ、ダッシュボードにグラフが表示されます。

以下の画像はダッシュボードの例です：

<Frame>
  ![](/images/tutorials/assets/images/experiments-1-aa7a86df71d0bf080e2240c416273c70.png)
</Frame>

W\&Bを疑似機械学習トレーニングループに統合する方法がわかったので、基本的なPyTorchニューラルネットワークを使用して機械学習実験を追跡しましょう。次のコードでは、モデルのチェックポイントをW\&Bにアップロードし、組織内の他のチームと共有することもできます。

## Pytorchを使用して機械学習実験を追跡する

次のコードセルは、シンプルなMNISTクラシファイアを定義してトレーニングします。トレーニング中、W\&BがURLを出力するのが見えます。プロジェクトページのリンクをクリックすると、結果がリアルタイムでW\&Bプロジェクトにストリーミングされるのを確認できます。

W\&B runは自動的に[metrics](/guides/runs#workspace-tab)、[system information](/guides/runs#system-tab)、[hyperparameters](/guides/runs#overview-tab)、[terminal output](/guides/runs#logs-tab)をログに記録し、[interactive table](/guides/tables)でモデルの入力と出力を確認できます。

### PyTorch Dataloaderのセットアップ

次のセルでは、機械学習モデルをトレーニングするために必要ないくつかの便利な関数を定義しています。これらの関数自体はW\&B特有のものではないため、ここでは詳細に説明しません。PyTorchのドキュメントを参照して、[forward and backward training loop](https://pytorch.org/tutorials/beginner/nn_tutorial.html)の定義方法、[PyTorch DataLoaders](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)を使用してトレーニングデータをロードする方法、[`torch.nn.Sequential` Class](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html)を使用してPyTorchモデルを定義する方法について確認してください。

```py
# @title
import torch, torchvision
import torch.nn as nn
from torchvision.datasets import MNIST
import torchvision.transforms as T

MNIST.mirrors = [
    mirror for mirror in MNIST.mirrors if "http://yann.lecun.com/" not in mirror
]

device = "cuda:0" if torch.cuda.is_available() else "cpu"


def get_dataloader(is_train, batch_size, slice=5):
    "Get a training dataloader"
    full_dataset = MNIST(
        root=".", train=is_train, transform=T.ToTensor(), download=True
    )
    sub_dataset = torch.utils.data.Subset(
        full_dataset, indices=range(0, len(full_dataset), slice)
    )
    loader = torch.utils.data.DataLoader(
        dataset=sub_dataset,
        batch_size=batch_size,
        shuffle=True if is_train else False,
        pin_memory=True,
        num_workers=2,
    )
    return loader


def get_model(dropout):
    "A simple model"
    model = nn.Sequential(
        nn.Flatten(),
        nn.Linear(28 * 28, 256),
        nn.BatchNorm1d(256),
        nn.ReLU(),
        nn.Dropout(dropout),
        nn.Linear(256, 10),
    ).to(device)
    return model


def validate_model(model, valid_dl, loss_func, log_images=False, batch_idx=0):
    "Compute performance of the model on the validation dataset and log a wandb.Table"
    model.eval()
    val_loss = 0.0
    with torch.inference_mode():
        correct = 0
        for i, (images, labels) in enumerate(valid_dl):
            images, labels = images.to(device), labels.to(device)

            # Forward pass ➡
            outputs = model(images)
            val_loss += loss_func(outputs, labels) * labels.size(0)

            # Compute accuracy and accumulate
            _, predicted = torch.max(outputs.data, 1)
            correct += (predicted == labels).sum().item()

            # Log one batch of images to the dashboard, always same batch_idx.
            if i == batch_idx and log_images:
                log_image_table(images, predicted, labels, outputs.softmax(dim=1))
    return val_loss / len(valid_dl.dataset), correct / len(valid_dl.dataset)
```

### 予測値と実際の値を比較するテーブルを作成する

次のセルはW\&B特有のものなので、詳しく見ていきましょう。

このセルでは`log_image_table`という関数を定義しています。技術的にはオプションですが、この関数はW\&B Tableオブジェクトを作成します。このテーブルオブジェクトを使用して、モデルが各画像に対して何を予測したかを示すテーブルを作成します。

より具体的には、各行はモデルに供給された画像と、予測値および実際の値（ラベル）で構成されます。

```py
def log_image_table(images, predicted, labels, probs):
    "Log a wandb.Table with (img, pred, target, scores)"
    # Create a wandb Table to log images, labels and predictions to
    table = wandb.Table(
        columns=["image", "pred", "target"] + [f"score_{i}" for i in range(10)]
    )
    for img, pred, targ, prob in zip(
        images.to("cpu"), predicted.to("cpu"), labels.to("cpu"), probs.to("cpu")
    ):
        table.add_data(wandb.Image(img[0].numpy() * 255), pred, targ, *prob.numpy())
    wandb.log({"predictions_table": table}, commit=False)
```

### モデルをトレーニングしてチェックポイントをアップロードする

次のコードはモデルをトレーニングし、モデルチェックポイントをプロジェクトに保存します。通常通りモデルチェックポイントを使用して、トレーニング中のモデルのパフォーマンスを評価できます。

W\&Bを使用すると、保存したモデルとモデルチェックポイントをチームや組織の他のメンバーと簡単に共有できます。チーム外のメンバーとモデルやモデルチェックポイントを共有する方法については、[W\&B Registry](/guides/registry)をご覧ください。

```py
# Launch 3 experiments, trying different dropout rates
for _ in range(3):
    # initialise a wandb run
    wandb.init(
        project="pytorch-intro",
        config={
            "epochs": 5,
            "batch_size": 128,
            "lr": 1e-3,
            "dropout": random.uniform(0.01, 0.80),
        },
    )

    # Copy your config
    config = wandb.config

    # Get the data
    train_dl = get_dataloader(is_train=True, batch_size=config.batch_size)
    valid_dl = get_dataloader(is_train=False, batch_size=2 * config.batch_size)
    n_steps_per_epoch = math.ceil(len(train_dl.dataset) / config.batch_size)

    # A simple MLP model
    model = get_model(config.dropout)

    # Make the loss and optimizer
    loss_func = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)

    # Training
    example_ct = 0
    step_ct = 0
    for epoch in range(config.epochs):
        model.train()
        for step, (images, labels) in enumerate(train_dl):
            images, labels = images.to(device), labels.to(device)

            outputs = model(images)
            train_loss = loss_func(outputs, labels)
            optimizer.zero_grad()
            train_loss.backward()
            optimizer.step()

            example_ct += len(images)
            metrics = {
                "train/train_loss": train_loss,
                "train/epoch": (step + 1 + (n_steps_per_epoch * epoch))
                / n_steps_per_epoch,
                "train/example_ct": example_ct,
            }

            if step + 1 < n_steps_per_epoch:
                # Log train metrics to wandb
                wandb.log(metrics)

            step_ct += 1

        val_loss, accuracy = validate_model(
            model, valid_dl, loss_func, log_images=(epoch == (config.epochs - 1))
        )

        # Log train and validation metrics to wandb
        val_metrics = {"val/val_loss": val_loss, "val/val_accuracy": accuracy}
        wandb.log({**metrics, **val_metrics})

        # Save the model checkpoint to wandb
        torch.save(model, "my_model.pt")
        wandb.log_model(
            "./my_model.pt",
            "my_mnist_model",
            aliases=[f"epoch-{epoch+1}_dropout-{round(wandb.config.dropout, 4)}"],
        )

        print(
            f"Epoch: {epoch+1}, Train Loss: {train_loss:.3f}, Valid Loss: {val_loss:3f}, Accuracy: {accuracy:.2f}"
        )

    # If you had a test set, this is how you could log it as a Summary metric
    wandb.summary["test_accuracy"] = 0.8

    # Close your wandb run
    wandb.finish()
```

これでW\&Bを使用した最初のモデルのトレーニングが完了しました。上記のリンクのいずれかをクリックして、メトリクスを確認し、W\&B App UIのArtifactsタブで保存されたモデルチェックポイントを確認してください。

## （オプション）W\&B Alertの設定

作成する[W\&B Alerts](/guides/runs/alert/)を使用して、Pythonコードからあなたのスラックやメールにアラートを送信します。

コードからSlackまたはメールアラートを送信するために初めて設定する場合は、以下の2つのステップに従ってください：

1. W\&Bの[User Settings](https://wandb.ai/settings)
2. で通知をオンにする`wandb.alert()`をコードに追加します。例えば：

```
wandb.alert(title="Low accuracy", text=f"Accuracy is below the acceptable threshold")
```

以下のセルは`wandb.alert`

```py
# Start a wandb run
wandb.init(project="pytorch-intro")

# Simulating a model training loop
acc_threshold = 0.3
for training_step in range(1000):

    # Generate a random number for accuracy
    accuracy = round(random.random() + random.random(), 3)
    print(f"Accuracy is: {accuracy}, {acc_threshold}")

    # Log accuracy to wandb
    wandb.log({"Accuracy": accuracy})

    # If the accuracy is below the threshold, fire a W&B Alert and stop the run
    if accuracy <= acc_threshold:
        # Send the wandb Alert
        wandb.alert(
            title="Low Accuracy",
            text=f"Accuracy {accuracy} at step {training_step} is below the acceptable theshold, {acc_threshold}",
        )
        print("Alert triggered")
        break

# Mark the run as finished (useful in Jupyter notebooks)
wandb.finish()
```

の使用方法を示す最小限の例です。[W\&B Alerts here](/guides/runs/alert)で完全なドキュメントを確認できます。

## 次のステップ

次のチュートリアルでは、W\&B Sweepsを使用したハイパーパラメータ最適化の方法を学びます：[PyTorchを使用したハイパーパラメータスイープ](https://colab.research.google.com/github/wandb/examples/blob/master/colabs/pytorch/Organizing_Hyperparameter_Sweeps_in_PyTorch_with_W%26B.ipynb)
