---
- title: 문제 해결
- description: Weave에서 발생할 수 있는 일반적인 문제에 대한 해결책과 지침
---

이 페이지는 발생할 수 있는 일반적인 문제에 대한 해결책과 지침을 제공합니다. 이 가이드를 계속 확장함에 따라 더 넓은 범위의 시나리오를 다루기 위해 더 많은 문제 해결 주제가 추가될 예정입니다.

<Tip>
  커뮤니티와 공유할 Weave 문제 해결 조언이 있으신가요? 이 가이드 하단의 **Edit this page**를 클릭하여 풀 리퀘스트를 제출하여 직접 기여하세요.
</Tip>

## 추적 페이지 로딩 속도가 느림

추적 페이지 로딩 속도가 느리면 표시되는 행 수를 줄여 로딩 시간을 개선하세요. 기본값은 `50`입니다. UI를 통해 또는 쿼리 매개변수를 사용하여 행 수를 줄일 수 있습니다.

### UI를 통해 조정(권장)

Traces 페이지 오른쪽 하단의 **Per page** 컨트롤을 사용하여 표시되는 행 수를 조정하세요. 기본값 `50` 외에도 `10`, `25`, 또는 `100`로 설정할 수 있습니다.

### 쿼리 매개변수 사용

수동 접근 방식을 선호하는 경우, 쿼리 URL의 `pageSize` 쿼리 매개변수를 최대값 `100` 미만의 값으로 수정할 수 있습니다.

## 서버 응답 캐싱

Weave는 반복되는 쿼리를 수행하거나 제한된 네트워크 대역폭으로 작업할 때 성능을 향상시키기 위해 서버 응답 캐싱을 제공합니다. 현재는 기본적으로 비활성화되어 있지만, 이 기능은 향후 릴리스에서 기본 동작이 될 것으로 예상됩니다.

### 캐싱을 사용해야 하는 경우

서버 응답 캐싱은 다음과 같은 경우에 특히 유용합니다:

* 동일한 쿼리를 자주 실행합니다
* 네트워크 대역폭이 제한되어 있습니다
* 지연 시간이 긴 환경에서 작업하고 있습니다
* 오프라인에서 개발 중이며 나중에 사용하기 위해 응답을 캐시하고 싶습니다

이 기능은 데이터셋에 대한 반복적인 평가를 실행할 때 특히 유용하며, 실행 간에 데이터셋을 캐싱할 수 있습니다.

### 캐싱 활성화 방법

캐싱을 활성화하려면 다음 환경 변수를 설정할 수 있습니다:

```bash
# Enable server response caching
export WEAVE_USE_SERVER_CACHE=true

# Set cache size limit (default is 1GB)
export WEAVE_SERVER_CACHE_SIZE_LIMIT=1000000000

# Set cache directory (optional, defaults to temporary directory)
export WEAVE_SERVER_CACHE_DIR=/path/to/cache
```

### 캐싱 동작

기술적으로, 이 기능은 서버에 대한 멱등성 요청을 캐시합니다. 구체적으로, 다음을 캐시합니다:

* `obj_read`
* `table_query`
* `table_query_stats`
* `refs_read_batch`
* `file_content_read`

### 캐시 크기 및 저장소 세부 정보

캐시 크기는 다음에 의해 제어됩니다 `WEAVE_SERVER_CACHE_SIZE_LIMIT` (바이트 단위). 실제 디스크 공간 사용량은 세 가지 구성 요소로 이루어집니다:

1. 32KB 크기의 체크섬 파일
2. 실행 중인 클라이언트당 최대 \~4MB의 선행 기록(WAL) 파일(프로그램 종료 시 자동으로 제거됨)
3. 최소 32KB에서 최대 `WEAVE_SERVER_CACHE_SIZE_LIMIT`

총 디스크 공간 사용량:

* 실행 중 >= 32KB + \~4MB + 캐시 크기
* 종료 후 >= 32KB + 캐시 크기

예를 들어, 5MB 캐시 제한의 경우:

* 실행 중: 최대 \~9MB
* 종료 후: 최대 \~5MB

## 추적 데이터가 잘림

때때로, 큰 추적 데이터가 Weave UI에서 부분적으로 잘릴 수 있습니다. 이 문제는 기본 추적 출력이 Weave가 직렬화하는 방법을 모르는 원시 커스텀 Python 객체이기 때문에 발생합니다.

큰 추적 데이터가 잘리지 않도록 하려면, 모든 추적 데이터를 반환하는 문자열 사전을 정의하세요.

```python
import weave

class MyObj:
    def __init__(self, x: int):
        self.x = x

    def __repr__(self):
        return f"MyObj(x={self.x})"

    def to_dict(self):
        return {"x": self.x}

@weave.op()
def make_my_obj():
    x = "s" * 10_000
    return MyObj(x)
```

## 긴 평가 정리 시간

큰 데이터셋으로 평가를 실행할 때 성능을 향상시키기 위해 다음 두 가지 방법을 함께 사용해야 합니다.

### 플러싱

큰 데이터셋으로 평가를 실행할 때, 데이터셋이 백그라운드 스레드에서 업로드되는 동안 프로그램 실행 전에 오랜 시간이 걸릴 수 있습니다. 이는 일반적으로 백그라운드 정리가 완료되기 전에 메인 스레드 실행이 끝났을 때 발생합니다. `client.flush()` 를 호출하면 모든 백그라운드 작업이 메인 스레드에서 처리되도록 강제하여 메인 스레드 실행 중에 병렬 처리를 보장합니다. 이는 사용자 코드가 데이터가 서버에 업로드되기 전에 완료될 때 성능을 향상시킬 수 있습니다.

Example:

```python
client = weave.init("fast-upload")

# ... evaluation setup
result = evaluation.Evaluate(dataset_id="my_dataset_id")

client.flush()
```

### 클라이언트 병렬 처리 증가

클라이언트 병렬 처리는 환경에 따라 자동으로 결정되지만, 다음 환경 변수를 사용하여 수동으로 설정할 수 있습니다:

* `WEAVE_CLIENT_PARALLELISM`: 병렬 처리에 사용 가능한 스레드 수입니다. 이 숫자를 늘리면 병렬 처리에 사용 가능한 스레드 수가 증가하여 데이터셋 업로드와 같은 백그라운드 작업의 성능이 향상될 수 있습니다.

이는 `settings` 인수를 `weave.init()`에 사용하여 프로그래밍 방식으로도 설정할 수 있습니다:

```python
client = weave.init("fast-upload", settings={"client_parallelism": 100})
```

## OS 오류

### `[Errno 24]: Too many open files`

이 오류는 열린 파일 수가 운영 체제에서 설정한 제한을 초과할 때 발생합니다. Weave에서는 대용량 이미지 데이터셋으로 작업할 때 이런 일이 발생할 수 있습니다. Weave는 이미지 처리를 위해 `PIL` 를 사용하며, 이는 프로그램 실행 동안 파일 디스크립터를 열어 둡니다.

이 문제를 해결하려면 열린 파일에 대한 시스템 제한을 `65,536` 로 늘리세요 `ulimit`:

```bash
ulimit -n 65536
```
