# TypeScript를 사용한 Weave 빠른 시작 가이드

W\&B Weave를 TypeScript와 함께 사용하여 다음을 수행할 수 있습니다:

* 언어 모델 입력, 출력 및 추적 로깅 및 디버깅
* 언어 모델 사용 사례에 대한 엄격하고 공정한 평가 구축
* 실험부터 평가, 프로덕션에 이르기까지 LLM 워크플로우에서 생성된 모든 정보 구성

자세한 내용은 [Weave 문서](/)를 참조하세요.

## 함수 추적

TypeScript 코드에서 Weave를 사용하려면 새 Weave 프로젝트를 초기화하고 추적하려는 함수에 `weave.op` 래퍼를 추가하세요.

추가 후 `weave.op` 함수를 호출하면 W\&B 대시보드에서 프로젝트 내에서 추적된 것을 확인할 수 있습니다.

코드가 자동으로 추적됩니다 - UI의 코드 탭을 확인하세요!

```typescript
async function initializeWeaveProject() {
    const PROJECT = 'weave-examples';
    await weave.init(PROJECT);
}
```

```typescript
const stripUserInput = weave.op(function stripUserInput(userInput: string): string {
    return userInput.trim();
});
```

다음 예제는 기본 함수 추적이 어떻게 작동하는지 보여줍니다.

```typescript
async function demonstrateBasicTracking() {
    const result = await stripUserInput("    hello    ");
    console.log('Basic tracking result:', result);
}
```

## OpenAI 통합

Weave는 다음을 포함한 모든 OpenAI 호출을 자동으로 추적합니다:

* 토큰 사용량
* API 비용
* 요청/응답 쌍
* 모델 구성

:::note
OpenAI 외에도 Weave는 Anthropic 및 Mistral과 같은 다른 LLM 제공업체의 자동 로깅을 지원합니다. 전체 목록은 [통합 문서의 LLM 제공업체](../../guides/integrations/index.md#llm-providers)를 참조하세요.
:::

```typescript
function initializeOpenAIClient() {
    return weave.wrapOpenAI(new OpenAI({
        apiKey: process.env.OPENAI_API_KEY
    }));
}
```

```typescript
async function demonstrateOpenAITracking() {
    const client = initializeOpenAIClient();
    const result = await client.chat.completions.create({
        model: "gpt-4-turbo",
        messages: [{ role: "user", content: "Hello, how are you?" }],
    });
    console.log('OpenAI tracking result:', result);
}
```

## 중첩 함수 추적

Weave를 사용하면 전체 실행 추적을 보존하면서 여러 추적 함수와 LLM 호출을 결합하여 복잡한 워크플로우를 추적할 수 있습니다. 이것의 이점은 다음과 같습니다:

* 애플리케이션의 로직 흐름에 대한 완전한 가시성
* 복잡한 작업 체인의 쉬운 디버깅
* 성능 최적화 기회

```typescript
async function demonstrateNestedTracking() {
    const client = initializeOpenAIClient();
    
    const correctGrammar = weave.op(async function correctGrammar(userInput: string): Promise<string> {
        const stripped = await stripUserInput(userInput);
        const response = await client.chat.completions.create({
            model: "gpt-4-turbo",
            messages: [
                {
                    role: "system",
                    content: "You are a grammar checker, correct the following user input."
                },
                { role: "user", content: stripped }
            ],
            temperature: 0,
        });
        return response.choices[0].message.content ?? '';
    });

    const grammarResult = await correctGrammar("That was so easy, it was a piece of pie!");
    console.log('Nested tracking result:', grammarResult);
}
```

## 데이터셋 관리

Weave를 사용하여 [`weave.Dataset`](../../guides/core-types/datasets.mdx) 클래스로 데이터셋을 생성하고 관리할 수 있습니다. [Weave `Models`](../../guides/core-types/models.mdx)와 유사하게, `weave.Dataset` helps:

* 데이터 추적 및 버전 관리
* 테스트 케이스 구성
* 팀원 간 데이터셋 공유
* 체계적인 평가 지원

```typescript
interface GrammarExample {
    userInput: string;
    expected: string;
}
```

```typescript
function createGrammarDataset(): weave.Dataset<GrammarExample> {
    return new weave.Dataset<GrammarExample>({
        id: 'grammar-correction',
        rows: [
            {
                userInput: "That was so easy, it was a piece of pie!",
                expected: "That was so easy, it was a piece of cake!"
            },
            {
                userInput: "I write good",
                expected: "I write well"
            },
            {
                userInput: "LLM's are best",
                expected: "LLM's are the best"
            }
        ]
    });
}
```

## 평가 프레임워크

Weave는 [`Evaluation` 클래스로 평가 중심 개발을 지원합니다](../../guides/core-types/evaluations.mdx). 평가는 GenAI 애플리케이션을 안정적으로 반복할 수 있도록 도와줍니다. `Evaluation` 클래스는 다음을 수행합니다:

* 평가 `Model` 성능 `Dataset`
* 사용자 정의 점수 함수 적용
* 상세한 성능 보고서 생성
* 모델 버전 간 비교 가능

전체 평가 튜토리얼은 [http://wandb.me/weave\_eval\_tut](http://wandb.me/weave_eval_tut)

```typescript
class OpenAIGrammarCorrector {
    private oaiClient: ReturnType<typeof weave.wrapOpenAI>;
    
    constructor() {
        this.oaiClient = weave.wrapOpenAI(new OpenAI({
            apiKey: process.env.OPENAI_API_KEY
        }));
        this.predict = weave.op(this, this.predict);
    }

    async predict(userInput: string): Promise<string> {
        const response = await this.oaiClient.chat.completions.create({
            model: 'gpt-4-turbo',
            messages: [
                { 
                    role: "system", 
                    content: "You are a grammar checker, correct the following user input." 
                },
                { role: "user", content: userInput }
            ],
            temperature: 0
        });
        return response.choices[0].message.content ?? '';
    }
}
```

```typescript
async function runEvaluation() {
    const corrector = new OpenAIGrammarCorrector();
    const dataset = createGrammarDataset();
    
    const exactMatch = weave.op(
        function exactMatch({ modelOutput, datasetRow }: { 
            modelOutput: string; 
            datasetRow: GrammarExample 
        }): { match: boolean } {
            return { match: datasetRow.expected === modelOutput };
        },
        { name: 'exactMatch' }
    );

    const evaluation = new weave.Evaluation({
        dataset,
        scorers: [exactMatch],
    });

    const summary = await evaluation.evaluate({
        model: weave.op((args: { datasetRow: GrammarExample }) => 
            corrector.predict(args.datasetRow.userInput)
        )
    });
    console.log('Evaluation summary:', summary);
}
```

다음 `main` 함수는 모든 데모를 실행합니다:

```typescript
async function main() {
    try {
        await initializeWeaveProject();
        await demonstrateBasicTracking();
        await demonstrateOpenAITracking();
        await demonstrateNestedTracking();
        await runEvaluation();
    } catch (error) {
        console.error('Error running demonstrations:', error);
    }
}
```
